{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Measuring Meaning & Sampling\n",
    "This week, we begin by \"begging, borrowing and stealing\" text from several\n",
    "contexts of human communication (e.g., PDFs, HTML, Word) and preparing it for\n",
    "machines to \"read\" and analyze so that we can begin to build our sample. This notebook outlines scraping text from the web, PDF and Word documents. Then we detail \"spidering\" or walking\n",
    "through hyperlinks to build samples of online content, and using APIs,\n",
    "Application Programming Interfaces, provided by webservices to access their\n",
    "content. Along the way, we will use regular expressions, outlined in the\n",
    "reading, to remove unwanted formatting and ornamentation. Next, we discuss\n",
    "various text encodings, filtering and data structures in which text can be\n",
    "placed for analysis. Finally, we ask you to begin building a corpus for preliminary analysis and articulate what your sample represents in context of your final project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a python package just for this course: lucem_illud. If you haven't installed this package, you should run the following code first. You don't need to install the package later; all you need to do is just to import the package with: import lucem_illud. For your final projects, you may find it useful to [read the lucem_illud source code](https://github.com/UChicago-Computational-Content-Analysis/lucem_illud/tree/main/lucem_illud) and modify your code for your own interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
      "  Cloning git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /private/var/folders/7n/47sl211117v2958gd5nysr5r0000gn/T/pip-req-build-bd7s3r71\n",
      "  Running command git clone -q git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /private/var/folders/7n/47sl211117v2958gd5nysr5r0000gn/T/pip-req-build-bd7s3r71\n",
      "  Resolved git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to commit bcb2d9c1b1ef39816b750912647fdf91f3d23fbc\n",
      "Requirement already satisfied: numpy in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.20.3)\n",
      "Requirement already satisfied: requests in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (2.26.0)\n",
      "Requirement already satisfied: pandas in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.3.4)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (8.4.0)\n",
      "Collecting pdfminer2\n",
      "  Downloading pdfminer2-20151206-py2.py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting GitPython\n",
      "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.7.1)\n",
      "Requirement already satisfied: seaborn in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.11.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (1.0.1)\n",
      "Requirement already satisfied: nltk in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.6.5)\n",
      "Requirement already satisfied: gensim in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (4.1.2)\n",
      "Requirement already satisfied: matplotlib in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (3.5.0)\n",
      "Collecting pyanno3\n",
      "  Downloading pyanno3-2.0.2.tar.gz (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 9.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (4.10.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 7.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.20.37-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (2.6.3)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting speechrecognition\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pysoundfile\n",
      "  Downloading PySoundFile-0.9.0.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-macosx_10_5_x86_64.macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.whl (573 kB)\n",
      "\u001b[K     |████████████████████████████████| 573 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (0.18.3)\n",
      "Requirement already satisfied: IPython in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from lucem-illud==8.0.1) (7.29.0)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.1-cp38-cp38-macosx_10_9_x86_64.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->lucem-illud==8.0.1) (2.3.1)\n",
      "Collecting botocore<1.24.0,>=1.23.37\n",
      "  Downloading botocore-1.23.37-py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 1.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.37->boto3->lucem-illud==8.0.1) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.37->boto3->lucem-illud==8.0.1) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.37->boto3->lucem-illud==8.0.1) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from gensim->lucem-illud==8.0.1) (5.2.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 230 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n",
      "Requirement already satisfied: backcall in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.2.0)\n",
      "Requirement already satisfied: appnope in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (0.1.2)\n",
      "Requirement already satisfied: decorator in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (3.0.20)\n",
      "Requirement already satisfied: pygments in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from IPython->lucem-illud==8.0.1) (58.0.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->IPython->lucem-illud==8.0.1) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->IPython->lucem-illud==8.0.1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->lucem-illud==8.0.1) (0.2.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->lucem-illud==8.0.1) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from nltk->lucem-illud==8.0.1) (4.62.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from pandas->lucem-illud==8.0.1) (2021.3)\n",
      "Collecting traits\n",
      "  Downloading traits-6.3.2-cp38-cp38-macosx_10_9_x86_64.whl (5.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.0 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi>=0.6 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from pysoundfile->lucem-illud==8.0.1) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.21)\n",
      "Requirement already satisfied: lxml>=2.3.2 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from python-docx->lucem-illud==8.0.1) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from requests->lucem-illud==8.0.1) (2021.10.8)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->lucem-illud==8.0.1) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->lucem-illud==8.0.1) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->lucem-illud==8.0.1) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->lucem-illud==8.0.1) (2.2.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp38-cp38-macosx_10_9_x86_64.whl (609 kB)\n",
      "\u001b[K     |████████████████████████████████| 609 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from spacy->lucem-illud==8.0.1) (2.11.3)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp38-cp38-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp38-cp38-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 333 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp38-cp38-macosx_10_9_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp38-cp38-macosx_10_9_x86_64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 21.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->lucem-illud==8.0.1) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/hsinkengling/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy->lucem-illud==8.0.1) (1.1.1)\n",
      "Building wheels for collected packages: lucem-illud, pyanno3, python-docx, wordcloud\n",
      "  Building wheel for lucem-illud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lucem-illud: filename=lucem_illud-8.0.1-py3-none-any.whl size=34963 sha256=bf0906357fd6fdbcc1d4b2d4e7d0fb3848d0ce44371437d25a4e61f2e70250b4\n",
      "  Stored in directory: /private/var/folders/7n/47sl211117v2958gd5nysr5r0000gn/T/pip-ephem-wheel-cache-71k52wmc/wheels/26/66/59/2c69dc2c9856ccf2d3eb274e5754cbb361d91e0a577f63c61d\n",
      "  Building wheel for pyanno3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyanno3: filename=pyanno3-2.0.2-py3-none-any.whl size=116978 sha256=8ce66aee042526bebc37eb877fee568dcc3bf044aa1c36effa3231545985faa4\n",
      "  Stored in directory: /Users/hsinkengling/Library/Caches/pip/wheels/bb/cc/80/ebf89ef149ee78f88547ca8cf11c61642d2d9cf6907b81c321\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=963820de57c8bdcec759cd20350519c97cd734ee3b489072c9d4e0db8f605d9a\n",
      "  Stored in directory: /Users/hsinkengling/Library/Caches/pip/wheels/32/b8/b2/c4c2b95765e615fe139b0b17b5ea7c0e1b6519b0a9ec8fb34d\n",
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordcloud: filename=wordcloud-1.8.1-cp38-cp38-macosx_10_9_x86_64.whl size=160340 sha256=7690e0178d8179072053f6c8fba2b1634ed76ea2eaf8c96f2f4868b116566255\n",
      "  Stored in directory: /Users/hsinkengling/Library/Caches/pip/wheels/4d/3f/0d/a2ba9b7895c9f1be89018b3141c3df3d4f9c786c882ccfbc3b\n",
      "Successfully built lucem-illud pyanno3 python-docx wordcloud\n",
      "Installing collected packages: murmurhash, jmespath, cymem, catalogue, wasabi, typer, srsly, smmap, pydantic, preshed, botocore, blis, traits, thinc, spacy-loggers, spacy-legacy, s3transfer, pathy, langcodes, gitdb, wordcloud, speechrecognition, spacy, python-docx, pysoundfile, pydub, pyanno3, pdfminer2, graphviz, GitPython, boto3, lucem-illud\n",
      "Successfully installed GitPython-3.1.26 blis-0.7.5 boto3-1.20.37 botocore-1.23.37 catalogue-2.0.6 cymem-2.0.6 gitdb-4.0.9 graphviz-0.19.1 jmespath-0.10.0 langcodes-3.3.0 lucem-illud-8.0.1 murmurhash-1.0.6 pathy-0.6.1 pdfminer2-20151206 preshed-3.0.6 pyanno3-2.0.2 pydantic-1.8.2 pydub-0.25.1 pysoundfile-0.9.0.post1 python-docx-0.8.11 s3transfer-0.5.0 smmap-5.0.0 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 speechrecognition-3.8.1 srsly-2.4.2 thinc-8.0.13 traits-6.3.2 typer-0.4.0 wasabi-0.9.0 wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "#installing lucem_illud package\n",
    "#lucem_illud is a Latin phrase meaning \"that light\", the insight we can discover in text data!\n",
    "#If you get an error like \"Access is denied\", try running the `pip` command on the command line as an administrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not familiar with jupyter notebook, you may wonder what the exclamation mark(!) at the beginning of the command does (or even what pip means). The exclamation mark enables us to execute Terminal commands in the notebook cells (e.g., run `!ls` to display files in the current folder).\n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "import lucem_illud #pip install git+git://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import requests #for http requests\n",
    "import bs4 #called `beautifulsoup4`, an html parser\n",
    "import pandas #gives us DataFrames\n",
    "import docx #reading MS doc files, install as `python-docx`\n",
    "\n",
    "#Stuff for pdfs\n",
    "#Install as `pdfminer2`\n",
    "import pdfminer.pdfinterp\n",
    "import pdfminer.converter\n",
    "import pdfminer.layout\n",
    "import pdfminer.pdfpage\n",
    "\n",
    "#These come with Python\n",
    "import re #for regexs\n",
    "import urllib.parse #For joining urls\n",
    "import io #for making http requests look like files\n",
    "import json #For Tumblr API responses\n",
    "import os.path #For checking if files exist\n",
    "import os #For making directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working on the following files/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/Content%20Analysis%2018.pdf'\n",
    "example_docx = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/macs6000_connecting_to_midway.docx'\n",
    "example_docx_save = 'example.docx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be\n",
    "provided to us from a pre-curated text archive, but sometimes we will need to\n",
    "download it. As a starting example we will attempt to download the wikipedia\n",
    "page on content analysis. The page is located at [https://en.wikipedia.org/wiki/\n",
    "Content_analysis](https://en.wikipedia.org/wiki/Content_analysis) so lets start\n",
    "with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is\n",
    "simply a request to the server to provide the contents given by some url. The\n",
    "other request we will be using in this class is called a POST request and\n",
    "requests the server to take some content we provide. While the Python standard\n",
    "library does have the ability do make GET requests we will be using the\n",
    "[_requests_](http://docs.python-requests.org/en/master/) package as it is _'the\n",
    "only Non-GMO HTTP library for Python'_...also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get(wikipedia_content_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get\n",
    "another number (e.g. 404) it likely means there was some kind of error, these\n",
    "codes are called HTTP response codes and a list of them can be found\n",
    "[here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response\n",
    "object contains all the data the server sent including the website's contents\n",
    "and the HTTP header. We are interested in the contents which we can access with\n",
    "the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"296cc375-e49f-4836-b061-a9b1aa860fa5\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":1065940520,\"wgRevisionId\":1065940520,\"wgArticleId\":473317,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles with short description\",\"Short description matches Wikidata\",\"Articles prone to spam from October 2017\",\"Articles with BNE identifiers\",\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get(wikipedia_content_analysis)\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we were looking for, because it is the start of the HTML that\n",
    "makes up the website. This is HTML and is meant to be read by computers. Luckily\n",
    "we have a computer to parse it for us. To do the parsing we will use [_Beautiful\n",
    "Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better parser\n",
    "than the one in the standard library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we proceed to Beautiful Soup, a digression about Python syntax, especially about objects and functions.\n",
    "For those who are not familiar with the syntax of python (or, if you're familiar with R programming), you might wonder what requests.get or wikiContentRequest.text mean. To understand this, you need to first understand what objects are. You may have heard that Python is an object oriented programming language (unlike the procedure oriented programming language, an example of which is R). Object is a set of variables (or, data) and functions into which you pass your data. So, in object oriented programming languages, like python, variables and functions are bunleded into objects.\n",
    "\n",
    "For example, let's look at wikiContentRequest. We use dir() function, which returns the list of attributes and functions of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__attrs__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_content',\n",
       " '_content_consumed',\n",
       " '_next',\n",
       " 'apparent_encoding',\n",
       " 'close',\n",
       " 'connection',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'is_permanent_redirect',\n",
       " 'is_redirect',\n",
       " 'iter_content',\n",
       " 'iter_lines',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next',\n",
       " 'ok',\n",
       " 'raise_for_status',\n",
       " 'raw',\n",
       " 'reason',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dir(wikiContentRequest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 'text' here. We used 'wikiContentRequest.text' to access 'text.' In other words, we use .(dot notation) to access functions from objects. wikiContentRequest has a set of functions, as shown above, and we used 'wikiContentRequest.text' to access one of them. By the way, dot notations do not necessarily refer to functions--it refers to anything that the entity contains. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the next step: BeautifulSoup, a Python library which extracts data from HTML and XML, and transforms HTML files into Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis\n",
      "\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "\n",
      "Jump to navigation\n",
      "Jump to search\n",
      "Research method for studying docu\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's still random whitespace and we have more than just\n",
    "the text of the article. This is because what we requested is the whole webpage,\n",
    "not just the text for the article.\n",
    "\n",
    "We want to extract only the text we care about, and in order to do this we will\n",
    "need to inspect the html. One way to do this is simply to go to the website with\n",
    "a browser and use its inspection or view source tool. If javascript or other\n",
    "dynamic loading occurs on the page, however, it is likely that what Python\n",
    "receives is not what you will see, so we will need to inspect what Python\n",
    "receives. To do this we can save the html `requests` obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open() is a function which literally opens and returns the file. This function has multiple modes, and, here, we used mode as 'w', which means: open a file for writing. And then, we use 'write' function to write on the empty file (content_analysis_save) that we created using open(content_analysis_save, mode='w', encoding='utf-8').} What did we write on this file? The text we got from wikiContentRequest.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's open the file (`wikipedia_content_analysis.html`) we just created with\n",
    "a web browser. It should look sort of like the original but without the images\n",
    "and formatting.\n",
    "\n",
    "As there is very little standardization on structuring webpages, figuring out\n",
    "how best to extract what you want is an art. Looking at this page it looks like\n",
    "all the main textual content is inside `<p>`(paragraph) tags within the `<body>`\n",
    "tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Asia \n",
      "\n",
      "Middle East\n",
      "\n",
      "Europe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another excursion for those who are not familiar with programming: for loop. For loop is used to iterate over a sequence. \"ContentPTags\" contains multiple paragraphs, each of which starts and ends with `<p>`. What the \"for pTag in contentPtags[:3]\" does here is: find each paragraph in contentPTags, which, here, we limited to the first three using contentPtags[:3], and then print each paragraph. So, we have three paragraphs. By the way, you can insert `<p>` in juputer notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the text from the page, split up by paragraph. If we wanted to\n",
    "get the section headers or references as well it would require a bit more work,\n",
    "but is doable.\n",
    "\n",
    "There is one more thing we might want to do before sending this text to be\n",
    "processed, remove the references indicators (`[2]`, `[3]` , etc). To do this we\n",
    "can use a short regular expression (regex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0                                       South Asia \\n\n",
      "1                                       Middle East\\n\n",
      "2                                            Europe\\n\n",
      "3                                     North America\\n\n",
      "4   Content analysis is the study of documents and...\n",
      "5   Practices and philosophies of content analysis...\n",
      "6   Computers are increasingly used in content ana...\n",
      "7   Content analysis is best understood as a broad...\n",
      "8   The simplest and most objective form of conten...\n",
      "9   A further step in analysis is the distinction ...\n",
      "10  Quantitative content analysis highlights frequ...\n",
      "11  Siegfried Kracauer provides a critique of quan...\n",
      "12  With the rise of common computing facilities l...\n",
      "13  By having contents of communication available ...\n",
      "14  Computer-assisted analysis can help with large...\n",
      "15  Robert Weber notes: \"To make valid inferences ...\n",
      "16  There are five types of texts in content analy...\n",
      "17  Content analysis is research using the categor...\n",
      "18  Over the years, content analysis has been appl...\n",
      "19  In recent times, particularly with the advent ...\n",
      "20  Quantitative content analysis has enjoyed a re...\n",
      "21  Content analysis can also be described as stud...\n",
      "22  Manifest content is readily understandable at ...\n",
      "23  Holsti groups fifteen uses of content analysis...\n",
      "24  He also places these uses into the context of ...\n",
      "25  The following table shows fifteen uses of cont...\n",
      "26  As a counterpoint, there are limits to the sco...\n",
      "27  The process of the initial coding scheme or ap...\n",
      "28  With either approach above, immersing oneself ...\n",
      "29                                                 \\n\n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    #strings starting with r are raw so their \\'s are not modifier characters\n",
    "    #If we didn't start with r the string would be: '\\\\[\\\\d+\\\\]'\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#convert to a DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we learned how to do for loop, you might get what we did here: using contentParagraphs = [], we made an empty list; and then, for each paragraph in contentPTags, we substituted every [\\d+\\] with '', i.e., removed every [\\d+\\], and then appended each paragraph (now without [\\d+\\]) to the empty list. As we can see, we have a dataframe, each row of which is each paragraph of contentPTags, without reference indicators. \n",
    "\n",
    "By the way, what does [\\d+\\] mean? If you are not familiar with regex, it is a way of specifying searches in text.\n",
    "A regex engine takes in the search pattern, in the above case `'\\[\\d+\\]'` and\n",
    "some string, the paragraph texts. Then it reads the input string one character\n",
    "at a time checking if it matches the search. Here the regex `'\\d'` matches\n",
    "number characters (while `'\\['` and `'\\]'` capture the braces on either side)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` containing all relevant text from the page ready to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(36, 37), match='2'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNumber = r'\\d'\n",
    "regexResults = re.search(findNumber, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "regexResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python the regex package (`re`) usually returns `Match` objects (you can have\n",
    "multiple pattern hits in a a single `Match`), to get the string that matched our\n",
    "pattern we can use the `.group()` method, and as we want the first one we will\n",
    "ask for the 0'th group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the first number, if we wanted the whole block of numbers we can\n",
    "add a wildcard `'+'` which requests 1 or more instances of the preceding\n",
    "character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134567890\n"
     ]
    }
   ],
   "source": [
    "findNumbers = r'\\d+'\n",
    "regexResults = re.search(findNumbers, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the whole block of numbers, there are a huge number of special\n",
    "characters in regex, for the full description of Python's implementation look at\n",
    "the [re docs](https://docs.python.org/3/library/re.html) there is also a short\n",
    "[tutorial](https://docs.python.org/3/howto/regex.html#regex-howto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 1</font>\n",
    "<font color=\"red\">Construct cells immediately below this that describe and download webcontent relating to your anticipated final project. Use beautiful soup and at least five regular expressions to extract relevant, nontrivial *chunks* of that content (e.g., cleaned sentences, paragraphs, etc.) to a pandas `Dataframe`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_1_url = 'https://www.vox.com/recode/22836368/amazon-antitrust-ftc-marketplace'\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36 Edg/96.0.1054.62'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_1_response = requests.get(exercise_1_url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1soup = bs4.BeautifulSoup(exercise_1_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The true cost of Amazon’s low prices'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1title = e1soup.find('h1', class_ = 'c-page-title').get_text()\n",
    "e1title.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sara Morrison'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1author = e1soup.find('span', class_ = 'c-byline__author-name').get_text()\n",
    "e1author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan 13, 2022,  9:00am EST'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1time = e1soup.find('time', {'data-ui': 'timestamp'}).get_text()\n",
    "e1time.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Critics say the “everything store” does too much. Is 2022 the year antitrust hawks come for Amazon?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1sub = e1soup.find('p', class_ = 'c-entry-summary p-dek').get_text()\n",
    "e1sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This story is part of a Recode series about Big Tech and antitrust. Over the next few weeks, we’ll cover what’s happening with Apple, Amazon, Facebook, Google, and Microsoft.\n",
      "On the heels of yet another year of record sales, Amazon is dealing with a couple of unwelcome updates in the new year. The Senate Judiciary Committee has announced it will soon be marking up the American Innovation and Choice Online Act, an antitrust bill targeting Amazon and other Big Tech companies. This follows reports that the Federal Trade Commission is ramping up its years-long antitrust investigation into Amazon’s cloud computing arm, Amazon Web Services, or AWS. \n",
      "It’s clearer now than ever that Amazon, which was allowed to grow mostly unhindered for more than two decades, is caught in the middle of an international effort to check Big Tech’s power.\n",
      "The Senate bill, one of several bipartisan antitrust bills in Congress, would prohibit Amazon from giving its products preferential treatment, among other things. It’s the bill that would affect the company the most, and the one it has been fighting hardest against. Meanwhile, the renewed scrutiny from the FTC about alleged anti-competitive behavior from AWS, which represents a significant and largely invisible source of Amazon’s profits, could threaten Amazon’s long-term dominance in a number of industries.  \n",
      "Just because a company is successful and dominates a market (or even several markets) doesn’t mean it’s violating any antitrust laws. But Amazon’s critics say it illegally uses its power to harm competition and consumers, particularly with its Marketplace, where outside, or third-party, businesses can sell their products to Amazon customers alongside Amazon’s own wares. Amazon has been accused of copying popular products to sell under its own labels, using non-public seller data to inform its own decisions, and forcing sellers into agreements that essentially prohibit them from offering lower prices elsewhere. Amazon denies some of these allegations and says other actions are simply meant to provide the services its customers want at the best price.\n",
      "Some of these complaints have been around a while, but 2022 may be the year that Amazon faces meaningful and real consequences for them. There are still caveats. State attorneys general are rumored to be looking into some of Amazon’s business practices, but only one has filed a lawsuit so far. The FTC is still waiting for the confirmation of a fifth Democratic commissioner who would break up the deadlock of two Republican and two Democratic commissioners. And while antitrust bills are making progress in Congress, Democratic lawmakers currently seem focused on other initiatives ahead of the midterm elections — elections that could give Republicans a majority in one or both houses of Congress. \n",
      "Amazon isn’t the only Big Tech company that’s been targeted, but it might have more reason than anyone else to worry about the FTC in particular. One of two federal agencies that enforce antitrust laws, the FTC is now run by Lina Khan, who basically built her career on research surrounding her 2017 Yale Law Journal paper, “Amazon’s Antitrust Paradox.” The paper detailed how Amazon’s rise showed the flaws in antitrust laws and led to Khan becoming known as Amazon’s antitrust antagonist. Since her appointment to the FTC last June, it hasn’t seemed like the question is whether the agency will take on Amazon, but rather when and how. Amazon, meanwhile, has asked that Khan recuse herself from any antitrust matters involving the company. \n",
      "Khan “is best suited to understand the various issues and problems with Amazon,” said Alex Harman, a competition policy advocate at Public Citizen, a consumer advocacy group. “And we are very excited that she will be able to bring a significant action against them.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lina Khan, a vocal Amazon critic, was appointed chair of the Federal Trade Commission last June.\n",
      "An Rong Xu/Washington Post via Getty Images\n",
      "\n",
      "\n",
      "Khan has a lot to choose from. It’s hard to overstate Amazon’s role in the economy, or how many roles it has. It’s a technology company. It’s a delivery service. It’s an advertising platform. It powers about a third of the internet. It’s a movie studio and a streaming service. It’s a health care provider. It’s a surveillance machine and a data harvester. It’s one of the largest employers in the world and one of the most valuable companies. Also, it sells books.\n",
      "In response to questions about whether its size and market share were too big in too many sectors, Amazon told Recode it faces “intense competition” in all of its lines of business. It says its expansion is part of a long-running strategy to make “big bets over the long term to reinvent the customer experience.”\n",
      "Sarah Miller, executive director of the American Economic Liberties Project, an anti-monopoly advocacy group, sees it differently: “Amazon leverages its power in one space to take over a new space, which is core to their business practice. They have the ability to combine the competitive advantages of different aspects of their business to take over new sectors of the economy.”\n",
      "While the FTC, for now, seems interested in AWS (and Amazon’s attempt to buy MGM), most of the antitrust attention we’ve seen elsewhere is focused on Amazon’s retail business and how it treats the businesses that sell products through its Marketplace platform. Critics say Amazon uses its power to give its own wares an unfair advantage over third-party sellers, and effectively forces them to pay for extra services and make agreements that could inflate prices everywhere. \n",
      "“That’s where there’s a lot of obvious harms, and where you have businesses who are unhappy with how they’re being treated,” Miller said.\n",
      "Consumers may be paying more and missing out on new products, companies, and innovations that a more competitive retail space would have produced. And that may be a violation of the antitrust laws we have now, or those to come.\n",
      "How Amazon’s power might lead to higher prices\n",
      "Many antitrust complaints about Amazon’s practices are based on its position as both a platform and a seller on that platform. This gives Amazon a great deal of power over the companies it’s competing against, as well as an incentive to favor its products over theirs. About 60 percent of Amazon’s online sales come through Marketplace. This can be a mutually beneficial relationship. Marketplace’s sellers — currently more than 2 million of them — get access to Amazon’s huge customer base, and Amazon gets a vastly expanded selection that has helped make it the first and only website many online shoppers visit. \n",
      "This model brings in hundreds of billions of dollars in revenue every year for Amazon, which now has an estimated 40 percent share of the e-commerce market in the United States. The company with the second-largest e-commerce market share, Walmart, has just 7 percent. At the same time, Amazon likes to say it has but a small sliver — 1 percent — of a competitive global retail market. But that’s online and offline combined, and it includes many industries in which Amazon doesn’t sell anything at all. Amazon is also on track to edge out Walmart and become the most dominant retailer, online and off, in the United States as soon as this year. \n",
      "No company has the kind of ecosystem Amazon built around its retail business beyond Marketplace. Amazon collects tons of data about its shoppers — data it uses to optimize its services and to fuel its burgeoning and increasingly lucrative advertising business. Meanwhile, Amazon Prime and its fast free shipping has not only created an intensely loyal customer base but also compelled Amazon to build up its own shipping and logistics arm, Fulfillment by Amazon, to reduce its reliance on outside services and give it more control over its sellers. Many of Amazon’s rival retailers — namely, Walmart and Target — do some or all of these things to a lesser extent, but they’re just playing catch-up.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Amazon is on track to take over from Walmart as the most dominant retailer in the US.\n",
      "Justin Sullivan/Getty Images\n",
      "\n",
      "\n",
      "Smaller companies simply don’t have the scale or money to offer such services. Amazon, which has turned itself from a bookstore to an “everything store” to an everything platform, is in a class by itself.\n",
      "“There are dynamics in digital that are fundamentally different,” Andrew Lipsman, principal analyst at eMarketer, told Recode. “Access to data is fundamentally different than we’ve ever had before. And all the other things that has enabled — all these digital businesses that Amazon has spun off — are underpinned by completely different economics than traditional retail economics.”\n",
      "Amazon is happy to tell you how good it’s been for the small- and medium-sized businesses making money using its platform and how proposed antitrust actions could harm them. Others argue that Amazon makes even more money off of third-party sellers who have to play by Amazon’s rules because their businesses wouldn’t survive without the e-commerce giant and its customer base. And those rules, they say, aren’t always fair.\n",
      "Last May, the attorney general of Washington, DC, Karl Racine, sued Amazon for antitrust violations over its treatment of Marketplace sellers. In September, he amended that lawsuit to include the wholesalers, or first-party sellers, from which Amazon buys products before selling them to its customers. \n",
      "Racine told Recode that he started to wonder what the price of Amazon’s much-touted “customer obsession” was, especially after seeing accusations that Amazon copied popular products on its platform and then sold its own similar products for a lower price. (Amazon says it’s standard practice for retailers to use data about customers’ interests to help determine what to make for their own private labels.)\n",
      "“I found that offensive,” Racine told Recode. “I felt like Amazon was just a copycat and burying a creative source. They were not focused only on the customer. They were also focused on their bottom line.”\n",
      "The DC attorney general’s office investigated and found that “Amazon, the dominant player, seeks to maximize its profits at the expense of consumers, third-party sellers, and wholesalers,” Racine said. “It’s kept prices for goods artificially high, hampered competition, stifled innovation, and illegally tilted the playing field, all in its favor.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Washington, DC, Attorney General Karl Racine sued Amazon for antitrust violations.\n",
      "Jahi Chikwendiu/Washington Post via Getty Images\n",
      "\n",
      "\n",
      "Racine’s suit echoes some of the issues raised in other lawsuits and investigations as well as those identified in a recent report from the Institute for Local Self-Reliance, a nonprofit that advocates for locally owned businesses. \n",
      "The big sticking point is that Amazon’s policies can effectively force other companies to give Amazon the lowest price for their goods. This is due to Amazon’s “fair pricing” policy, which says it can downgrade or stop sales of third-party sellers’ products if they’re priced “significantly higher” on Amazon than at other outlets. Meanwhile, wholesalers have to agree to give Amazon a certain cut of their products’ sales. But Amazon also sets the prices of those products. If it reduces them to price match another outlet, the wholesaler may end up eating the difference and even losing money. That keeps wholesalers from selling their wares to anyone else for less.\n",
      "Amazon sees all this as looking out for its customers and making sure they’re getting the lowest prices. But Racine and those who have filed similar lawsuits believe sellers and wholesalers are being stopped from selling their products for lower prices in other stores. Because of this, competitors can’t offer lower prices to get an advantage over Amazon, and customers end up paying Amazon’s prices even if they don’t shop at Amazon — and paying more. Sellers and wholesalers can choose not to sell to Amazon, but few of them have the size and brand recognition needed to survive in a world where so many shoppers do most, if not all, of their online shopping on Amazon.\n",
      "“That’s the power of brands: Nike is able to say, ‘You know what, Amazon? We don’t need you,’” Lipsman said. “The more commoditized your product is, the more likely you have to sell through Amazon, and you’re dependent on that channel.”\n",
      "Amazon has filed a motion to dismiss the DC attorney general’s lawsuit, arguing that it’s simply making sure its customers are getting the lowest prices. The policies don’t force sellers to offer the lowest price on Amazon, Amazon says; they simply discourage them from offering higher prices on Amazon than they do elsewhere. But this hasn’t always been the case. Just a few years ago, Amazon had a price parity policy, which more explicitly said sellers couldn’t offer lower prices anywhere else. Amazon ended this practice in Europe years ago amid scrutiny there, and then did the same thing in the United States in 2019. Racine says the fair pricing policy that replaced it serves the same function and is similarly anti-competitive.\n",
      "How Amazon uses its power over sellers to squeeze them for money and data\n",
      "Even though one of Amazon’s selling points is its low prices, critics say those aren’t necessarily the lowest prices possible, in part due to the increasing costs to sell on Marketplace. Amazon charges sellers a referral fee, typically 15 percent, for items sold. Then it piles on optional services that many sellers feel compelled to buy if they want their businesses to survive, cutting into their margins and forcing some to raise their prices to maintain a profit. \n",
      "Fulfillment by Amazon, or FBA, is one example of this. Amazon doesn’t require that its sellers use its fulfillment and shipping service, but doing so makes them eligible for Prime, and it’s exceedingly difficult to qualify for Prime if they don’t. \n",
      "That recognizable Prime badge is important. There’s a higher likelihood that Amazon’s customers will buy Prime products, because the shipping is free for Prime members and because Amazon gives preference to Prime items when it assigns what’s known as the “Buy Box.” When multiple sellers offer the same product, the Buy Box winner is added to carts when customers click “buy.” More than 80 percent of an item’s sales go to the Buy Box winner, so sellers are very motivated to do everything possible to get it. That may include using FBA even if it costs them more than shipping items themselves.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Workers at one of Amazon’s many fulfillment centers prepare packages for delivery.\n",
      "Johannes Eisele/AFP via Getty Images\n",
      "\n",
      "\n",
      "This practice has already gotten Amazon into trouble abroad. In December, Italy’s antitrust regulators fined Amazon about $1.3 billion for giving sellers who use FBA benefits over those who don’t. Amazon says it’s planning to appeal the decision, but more trouble could be on the way: The company is facing a similar investigation from the European Union’s European Commission, and India is also investigating Amazon for violating its antitrust laws. \n",
      "Sellers have also complained about ads, which give their items better placement in search results. Reports say that Amazon has increased the number of ads, upping its revenue and pushing organic results down even further — which, in turn, compels sellers to buy ads to regain the prominent placement they used to get for free. Amazon told Recode that sellers wouldn’t use FBA or buy ads if those services didn’t add value or come at the best price, as they can always use other fulfillment services and buy ads elsewhere.\n",
      "But it’s not just fees that Amazon gets from its sellers. Critics say the company uses data it collects from third-party sellers to give itself a competitive advantage. This was the subject of a “statement of objections” from the European Union, and as the DC attorney general has made clear, Amazon is notorious for creating its own versions of popular products sold by third parties. The company recently opened up some of its data to sellers, possibly in an effort to ward off some of this criticism, and says it prohibits the use of non-public data about individual sellers to develop its own products. But founder Jeff Bezos told Congress he couldn’t guarantee that policy has never been violated, and multiple press reports suggest that it has.\n",
      "The company has also been accused of self-preferencing, or giving its products preferential treatment — and a competitive advantage — over those sold by third parties. This could take the form of giving its own products the Buy Box or prominent search rankings they didn’t earn. Amazon has total control over its platform, so the company can really do whatever it wants, and there isn’t much sellers can do about it. \n",
      "Self-preferencing has become a catch-all term for many of Amazon’s alleged anti-competitive practices. It’s attracted the most attention from regulators so far. The company denies that it gives preference to its own items in search results and says the reports that it does are inaccurate. Many legislators aren’t buying that and have proposed bills forbidding self-preferencing, with Amazon specifically in mind.\n",
      "How Amazon could be changed by new antitrust laws\n",
      "Per its policies, the FTC has stayed mum on what, if anything, it’s investigating on Amazon. Congress, on the other hand, has been very public. \n",
      "The House Judiciary Committee spent 16 months looking into competition and digital markets, focusing on Amazon as well as Apple, Google, and Facebook. Last year, a bipartisan and mostly bicameral group of lawmakers proposed a package of Big Tech-focused antitrust bills. The House’s bills made it through committee markup last June, but have yet to be put to a vote. \n",
      "The American Innovation and Choice Online Act is the only Senate bill to be scheduled for markup so far. The House’s Ending Platform Monopolies Act, which still doesn’t have a Senate equivalent, is likely the most expansive of the bills in the antitrust package, forbidding dominant digital platforms from owning lines of business that incentivize them to give their own products and services preference over third parties. Should that bill become law, it could have a huge impact on Amazon, forcing it to split off its first-party store from its sales platform. \n",
      "Amazon has fought back against the bills. It has sent emails to certain sellers and set up an informational website warning them about how the bills, if they become law, could negatively impact them. Amazon claims that it might have to shut down Marketplace or limit its ability to offer Prime services. The bills’ supporters say that companies would still be able to offer all of those services, but could finally compete on a level playing field.\n",
      "“We urge Congress to consider these consequences instead of rushing through this ambiguously worded bill,” Brian Huseman, Amazon vice president of public policy, told Recode in a statement. He added that the bills should apply “to all retailers, not just one.”\n",
      "While Amazon waits to see what the FTC and Congress do, its antitrust battles, real and potential, haven’t seemed to harm its bottom line. Business is good, growing, and disruptive. Amazon is even reportedly preparing to take on Shopify, a platform that helps businesses create their own online shops and has grown exponentially during the pandemic, with a similar offering that could come out as early as this year. If true (Amazon wouldn’t comment), it shows that Amazon isn’t afraid of going after potential threats even while under more scrutiny than it’s ever experienced.\n",
      "That’s exactly the attitude Racine, the DC attorney general, takes issue with. “Amazon claims to be all about consumers,” he said. “What our evidence shows is that Amazon is all about more profit for Amazon, at the cost of competition and at the expense of consumers. And we’re looking forward to proving that in court.”\n",
      "\n",
      "\n",
      "Will you support Vox’s explanatory journalism?\n",
      "\n",
      "    Millions turn to Vox to understand what’s happening in the news. Our mission has never been more vital than it is in this moment: to empower through understanding. Financial contributions from our readers are a critical part of supporting our resource-intensive work and help us keep our journalism free for all.  Please consider making a contribution to Vox today to help us keep our work free for all.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e1par = e1soup.find('div', class_ = 'c-entry-content').get_text()\n",
    "print(e1par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Amazon’s Antitrust Paradox.”',\n",
       " '“is best suited to understand the various issues and problems with Amazon,” said Alex Harman, a competition policy advocate at Public Citizen, a consumer advocacy group. “And we are very excited that she will be able to bring a significant action against them.”',\n",
       " '“intense competition” in all of its lines of business. It says its expansion is part of a long-running strategy to make “big bets over the long term to reinvent the customer experience.”',\n",
       " '“Amazon leverages its power in one space to take over a new space, which is core to their business practice. They have the ability to combine the competitive advantages of different aspects of their business to take over new sectors of the economy.”',\n",
       " '“That’s where there’s a lot of obvious harms, and where you have businesses who are unhappy with how they’re being treated,”',\n",
       " '“everything store”',\n",
       " '“There are dynamics in digital that are fundamentally different,” Andrew Lipsman, principal analyst at eMarketer, told Recode. “Access to data is fundamentally different than we’ve ever had before. And all the other things that has enabled — all these digital businesses that Amazon has spun off — are underpinned by completely different economics than traditional retail economics.”',\n",
       " '“customer obsession”',\n",
       " '“I found that offensive,” Racine told Recode. “I felt like Amazon was just a copycat and burying a creative source. They were not focused only on the customer. They were also focused on their bottom line.”',\n",
       " '“Amazon, the dominant player, seeks to maximize its profits at the expense of consumers, third-party sellers, and wholesalers,” Racine said. “It’s kept prices for goods artificially high, hampered competition, stifled innovation, and illegally tilted the playing field, all in its favor.”',\n",
       " '“fair pricing” policy, which says it can downgrade or stop sales of third-party sellers’ products if they’re priced “significantly higher”',\n",
       " '“That’s the power of brands: Nike is able to say, ‘You know what, Amazon? We don’t need you,’” Lipsman said. “The more commoditized your product is, the more likely you have to sell through Amazon, and you’re dependent on that channel.”',\n",
       " '“Buy Box.” When multiple sellers offer the same product, the Buy Box winner is added to carts when customers click “buy.”',\n",
       " '“statement of objections”',\n",
       " '“We urge Congress to consider these consequences instead of rushing through this ambiguously worded bill,” Brian Huseman, Amazon vice president of public policy, told Recode in a statement. He added that the bills should apply “to all retailers, not just one.”',\n",
       " '“Amazon claims to be all about consumers,” he said. “What our evidence shows is that Amazon is all about more profit for Amazon, at the cost of competition and at the expense of consumers. And we’re looking forward to proving that in court.”']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex 1: quotes\n",
    "quotes = re.findall(r'\\“.+\\”', e1par)\n",
    "quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS',\n",
       " 'FTC',\n",
       " 'AWS',\n",
       " 'FTC',\n",
       " 'FTC',\n",
       " 'FTC',\n",
       " 'FTC',\n",
       " 'FTC',\n",
       " 'AWS',\n",
       " 'MGM',\n",
       " 'US',\n",
       " 'DC',\n",
       " 'DC',\n",
       " 'DC',\n",
       " 'DC',\n",
       " 'FBA',\n",
       " 'FBA',\n",
       " 'AFP',\n",
       " 'FBA',\n",
       " 'FBA',\n",
       " 'DC',\n",
       " 'FTC',\n",
       " 'FTC',\n",
       " 'DC']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex 2: acronyms\n",
    "acronyms = re.findall(r'([A-Z]{2,})', e1par)\n",
    "acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big Tech', ' Tech'),\n",
       " ('The Senate Judiciary Committee', ' Committee'),\n",
       " ('American Innovation', ' Innovation'),\n",
       " ('Choice Online Act', ' Act'),\n",
       " ('Big Tech', ' Tech'),\n",
       " ('Federal Trade Commission', ' Commission'),\n",
       " ('Amazon Web Services', ' Services'),\n",
       " ('Big Tech', ' Tech'),\n",
       " ('The Senate', ' Senate'),\n",
       " ('But Amazon', ' Amazon'),\n",
       " ('The FTC', ' FTC'),\n",
       " ('Big Tech', ' Tech'),\n",
       " ('Lina Khan', ' Khan'),\n",
       " ('Yale Law Journal', ' Journal'),\n",
       " ('Antitrust Paradox', ' Paradox'),\n",
       " ('Alex Harman', ' Harman'),\n",
       " ('Public Citizen', ' Citizen'),\n",
       " ('Lina Khan', ' Khan'),\n",
       " ('Federal Trade Commission', ' Commission'),\n",
       " ('An Rong Xu', ' Xu'),\n",
       " ('Washington Post', ' Post'),\n",
       " ('Getty Images\\n\\n\\nKhan', '\\n\\n\\nKhan'),\n",
       " ('Sarah Miller', ' Miller'),\n",
       " ('American Economic Liberties Project', ' Project'),\n",
       " ('How Amazon', ' Amazon'),\n",
       " ('United States', ' States'),\n",
       " ('United States', ' States'),\n",
       " ('Amazon Prime', ' Prime'),\n",
       " ('Justin Sullivan', ' Sullivan'),\n",
       " ('Getty Images\\n\\n\\nSmaller', '\\n\\n\\nSmaller'),\n",
       " ('Andrew Lipsman', ' Lipsman'),\n",
       " ('Last May', ' May'),\n",
       " ('Karl Racine', ' Racine'),\n",
       " ('In September', ' September'),\n",
       " ('The DC', ' DC'),\n",
       " ('Attorney General Karl Racine', ' Racine'),\n",
       " ('Jahi Chikwendiu', ' Chikwendiu'),\n",
       " ('Washington Post', ' Post'),\n",
       " ('Getty Images\\n\\n\\nRacine', '\\n\\n\\nRacine'),\n",
       " ('Local Self-Reliance', ' Self-Reliance'),\n",
       " ('But Amazon', ' Amazon'),\n",
       " ('But Racine', ' Racine'),\n",
       " ('United States', ' States'),\n",
       " ('How Amazon', ' Amazon'),\n",
       " ('Buy Box', ' Box'),\n",
       " ('Buy Box', ' Box'),\n",
       " ('Buy Box', ' Box'),\n",
       " ('Johannes Eisele', ' Eisele'),\n",
       " ('Getty Images\\n\\n\\nThis', '\\n\\n\\nThis'),\n",
       " ('In December', ' December'),\n",
       " ('European Union', ' Union'),\n",
       " ('European Commission', ' Commission'),\n",
       " ('European Union', ' Union'),\n",
       " ('Jeff Bezos', ' Bezos'),\n",
       " ('Buy Box', ' Box'),\n",
       " ('How Amazon', ' Amazon'),\n",
       " ('The House Judiciary Committee', ' Committee'),\n",
       " ('Big Tech-focused', ' Tech-focused'),\n",
       " ('The House', ' House'),\n",
       " ('The American Innovation', ' Innovation'),\n",
       " ('Choice Online Act', ' Act'),\n",
       " ('The House', ' House'),\n",
       " ('Ending Platform Monopolies Act', ' Act'),\n",
       " ('Brian Huseman', ' Huseman'),\n",
       " ('While Amazon', ' Amazon')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex 3: names\n",
    "names = re.findall(r'([A-Z][\\w-]*(\\s+[A-Z][\\w-]*)+)', e1par)\n",
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(or even several markets)',\n",
       " '(and Amazon’s attempt to buy MGM)',\n",
       " '(Amazon says it’s standard practice for retailers to use data about customers’ interests to help determine what to make for their own private labels.)',\n",
       " '(Amazon wouldn’t comment)']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex 4: parentheses\n",
    "parentheses = re.findall(r'\\(.+\\)', e1par)\n",
    "parentheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('years-long', '-long'),\n",
       " ('anti-competitive', '-competitive'),\n",
       " ('long-term', '-term'),\n",
       " ('third-party', '-party'),\n",
       " ('non-public', '-public'),\n",
       " ('long-running', '-running'),\n",
       " ('anti-monopoly', '-monopoly'),\n",
       " ('third-party', '-party'),\n",
       " ('e-commerce', '-commerce'),\n",
       " ('second-largest', '-largest'),\n",
       " ('e-commerce', '-commerce'),\n",
       " ('catch-up', '-up'),\n",
       " ('medium-sized', '-sized'),\n",
       " ('third-party', '-party'),\n",
       " ('e-commerce', '-commerce'),\n",
       " ('first-party', '-party'),\n",
       " ('much-touted', '-touted'),\n",
       " ('third-party', '-party'),\n",
       " ('Self-Reliance', '-Reliance'),\n",
       " ('third-party', '-party'),\n",
       " ('anti-competitive', '-competitive'),\n",
       " ('third-party', '-party'),\n",
       " ('non-public', '-public'),\n",
       " ('self-preferencing', '-preferencing'),\n",
       " ('Self-preferencing', '-preferencing'),\n",
       " ('catch-all', '-all'),\n",
       " ('anti-competitive', '-competitive'),\n",
       " ('self-preferencing', '-preferencing'),\n",
       " ('Tech-focused', '-focused'),\n",
       " ('first-party', '-party'),\n",
       " ('resource-intensive', '-intensive')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex 5: hyphenated words\n",
    "hyphen = re.findall(r'(\\w+(\\-\\w+){1,})', e1par)\n",
    "hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 13, 2022,  9:00am EST</td>\n",
       "      <td>Sara Morrison</td>\n",
       "      <td>The true cost of Amazon’s low prices</td>\n",
       "      <td>Critics say the “everything store” does too mu...</td>\n",
       "      <td>\\n\\nThis story is part of a Recode series abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time         author  \\\n",
       "1  Jan 13, 2022,  9:00am EST  Sara Morrison   \n",
       "\n",
       "                                  title  \\\n",
       "1  The true cost of Amazon’s low prices   \n",
       "\n",
       "                                            subtitle  \\\n",
       "1  Critics say the “everything store” does too mu...   \n",
       "\n",
       "                                             content  \n",
       "1  \\n\\nThis story is part of a Recode series abou...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1df = pandas.DataFrame(data = {'time': e1time.strip(),\n",
    "                         'author': e1author,\n",
    "                         'title': e1title.strip(),\n",
    "                         'subtitle': e1sub,\n",
    "                         'content': e1par},\n",
    "                index = [1])\n",
    "e1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(url):\n",
    "    '''\n",
    "    Add a row of data to current dataframe\n",
    "    '''\n",
    "    response = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    title = soup.find('h1', class_ = 'c-page-title').get_text().strip()\n",
    "    author = soup.find('span', class_ = 'c-byline__author-name').get_text()\n",
    "    time = soup.find('time', {'data-ui': 'timestamp'}).get_text().strip()\n",
    "    sub = soup.find('p', class_ = 'c-entry-summary p-dek').get_text()\n",
    "    par = soup.find('div', class_ = 'c-entry-content').get_text()\n",
    "    new_df = pandas.DataFrame(data = {'time': time,\n",
    "                            'author': author,\n",
    "                            'title': title,\n",
    "                            'subtitle': sub,\n",
    "                            'content': par},\n",
    "                             index = [1])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = add_data('https://www.vox.com/the-goods/22880345/pandemic-shopper-convenience-instant-delivery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 13, 2022,  7:00am EST</td>\n",
       "      <td>Terry Nguyen</td>\n",
       "      <td>The empty promise of instant delivery</td>\n",
       "      <td>The pandemic changed how shoppers think about ...</td>\n",
       "      <td>\\nAs a resident of New York City, I face long ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time        author  \\\n",
       "1  Jan 13, 2022,  7:00am EST  Terry Nguyen   \n",
       "\n",
       "                                   title  \\\n",
       "1  The empty promise of instant delivery   \n",
       "\n",
       "                                            subtitle  \\\n",
       "1  The pandemic changed how shoppers think about ...   \n",
       "\n",
       "                                             content  \n",
       "1  \\nAs a resident of New York City, I face long ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 13, 2022,  9:00am EST</td>\n",
       "      <td>Sara Morrison</td>\n",
       "      <td>The true cost of Amazon’s low prices</td>\n",
       "      <td>Critics say the “everything store” does too mu...</td>\n",
       "      <td>\\n\\nThis story is part of a Recode series abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan 13, 2022,  7:00am EST</td>\n",
       "      <td>Terry Nguyen</td>\n",
       "      <td>The empty promise of instant delivery</td>\n",
       "      <td>The pandemic changed how shoppers think about ...</td>\n",
       "      <td>\\nAs a resident of New York City, I face long ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time         author  \\\n",
       "1  Jan 13, 2022,  9:00am EST  Sara Morrison   \n",
       "1  Jan 13, 2022,  7:00am EST   Terry Nguyen   \n",
       "\n",
       "                                   title  \\\n",
       "1   The true cost of Amazon’s low prices   \n",
       "1  The empty promise of instant delivery   \n",
       "\n",
       "                                            subtitle  \\\n",
       "1  Critics say the “everything store” does too mu...   \n",
       "1  The pandemic changed how shoppers think about ...   \n",
       "\n",
       "                                             content  \n",
       "1  \\n\\nThis story is part of a Recode series abou...  \n",
       "1  \\nAs a resident of New York City, I face long ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1df.append(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Spidering\n",
    "\n",
    "What if we want to to get a bunch of different pages from wikipedia. We would\n",
    "need to get the url for each of the pages we want. Typically, we want pages that\n",
    "are linked to by other pages and so we will need to parse pages and identify the\n",
    "links. Right now we will be retrieving all links in the body of the content\n",
    "analysis page.\n",
    "\n",
    "To do this we will need to find all the `<a>` (anchor) tags with `href`s\n",
    "(hyperlink references) inside of `<p>` tags. `href` can have many\n",
    "[different](http://stackoverflow.com/questions/4855168/what-is-href-and-why-is-\n",
    "it-used) [forms](https://en.wikipedia.org/wiki/Hyperlink#Hyperlinks_in_HTML) so\n",
    "dealing with them can be tricky, but generally, you will want to extract\n",
    "absolute or relative links. An absolute link is one you can follow without\n",
    "modification, while a relative link requires a base url that you will then\n",
    "append. Wikipedia uses relative urls for its internal links: below is an example\n",
    "for dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#We also want to know where the links come from so we also will get:\n",
    "#the paragraph number\n",
    "#the word the link is in\n",
    "for paragraphNum, pTag in enumerate(contentPTags):\n",
    "    #we only want hrefs that link to wiki pages\n",
    "    tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #We need to extract the url from the <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        #wikipedia_base_url is the base we can use the urllib joining function to merge them\n",
    "        #Giving a nice structured tupe like this means we can use tuple expansion later\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contentPTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another excursion: Why do we use enumerate() here? enumerate() takes a collection, enumerates, and returns an enumate object with both the numbers and the collection. For example, contentPTags (the collection we used here) is comprised of paragraphs. We want the paragraph number of each paragraph. And this is what enumerate() does: it returns the paragraph number and the paragraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be adding these new texts to our DataFrame `contentParagraphsDF` so we\n",
    "will need to add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add two more columns to our `Dataframe` and define a function to\n",
    "parse\n",
    "each linked page and add its text to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentParagraphsDF['source-paragraph-number'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['source-paragraph-text'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Make a dict to store data before adding it to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [],  'source-paragraph-text' : []}\n",
    "    #Now we get the page\n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(targetURL)\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our list of link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for urlTuple in otherPAgeURLS[:3]:\n",
    "    #ignore_index means the indices will not be reset after each append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color=\"red\">Exercise 2</font>\n",
    "<font color=\"red\">Construct cells immediately below this that spider webcontent from another site with content relating to your anticipated final project. Specifically, identify urls on a core page, then follow and extract content from them into a pandas `Dataframe`. In addition, demonstrate a *recursive* spider, which follows more than one level of links (i.e., follows links from a site, then follows links on followed sites to new sites, etc.), making sure to define a reasonable endpoint so that you do not wander the web forever :-).</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4035366103.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/7n/47sl211117v2958gd5nysr5r0000gn/T/ipykernel_62225/4035366103.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    links = re.findall(r'<a\\s+href=(?:\"([^\"]+)\"|'([^']+)').*?>(.*?)</a>', response.text)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def recursive_keyword(max_loops, starting_url):\n",
    "    for loop_num in max_loops:\n",
    "        response = requests.get(starting_url)\n",
    "            links = re.findall(r'<a\\s+href=(?:\"([^\"]+)\"|'([^']+)').*?>(.*?)</a>', response.text)\n",
    "        recursive_keyword()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.youtube.com/watch?v=tsZCoJMoxv4&ab_channel=%E9%99%B3%E5%AF%97NingSelect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(response.text, parser = 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lst = recursive_keyword(10, 'https://www.youtube.com/results?search_query=%E5%9C%8B%E6%96%87%E4%BD%9C%E6%96%87')\n",
    "url_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API (Tumblr)\n",
    "\n",
    "Generally website owners do not like you scraping their sites. If done badly,\n",
    "scarping can act like a DOS attack so you should be careful how often you make\n",
    "calls to a site. Some sites want automated tools to access their data, so they\n",
    "create [application programming interface\n",
    "(APIs)](https://en.wikipedia.org/wiki/Application_programming_interface). An API\n",
    "specifies a procedure for an application (or script) to access their data. Often\n",
    "this is though a [representational state transfer\n",
    "(REST)](https://en.wikipedia.org/wiki/Representational_state_transfer) web\n",
    "service, which just means if you make correctly formatted HTTP requests they\n",
    "will return nicely formatted data.\n",
    "\n",
    "A nice example for us to study is [Tumblr](https://www.tumblr.com), they have a\n",
    "[simple RESTful API](https://www.tumblr.com/docs/en/api/v1) that allows you to\n",
    "read posts without any complicated html parsing.\n",
    "\n",
    "We can get the first 20 posts from a blog by making an http GET request to\n",
    "`'http://{blog}.tumblr.com/api/read/json'`, were `{blog}` is the name of the\n",
    "target blog. Lets try and get the posts from [http://lolcats-lol-\n",
    "cat.tumblr.com/](http://lolcats-lol-cat.tumblr.com/) (Note the blog says at the\n",
    "top 'One hour one pic lolcats', but the canonical name that Tumblr uses is in\n",
    "the URL 'lolcats-lol-cat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var tumblr_api_read = {\"tumblelog\":{\"title\":\"One hour one pic lolcats\",\"description\":\"\",\"name\":\"lolcats-lol-cat\",\"timezone\":\"Europe\\/Paris\",\"cname\":false,\"feeds\":[]},\"posts-start\":0,\"posts-total\":3925,\"posts-type\":false,\"posts\":[{\"id\":\"662815854023655425\",\"url\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/662815854023655425\",\"url-with-slug\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/662815854023655425\",\"type\":\"photo\",\"date-gmt\":\"2021-09-20 04:00:56 GMT\",\"date\":\"Mon, 20 Sep 2021 06:00:56\",\"bookmarklet\":0,\"mobile\":0,\"feed-item\":\"\",\"from-feed-id\":0,\"unix-timestamp\":1632110456,\"format\":\"html\",\"reblog-key\":\"kjH8cg34\",\"slug\":\"\",\"is-submission\":false,\"like-button\":\"<div class=\\\"like_button\\\" data-post-id=\\\"662815854023655425\\\" data-blog-name=\\\"lolcats-lol-cat\\\" id=\\\"like_button_662815854023655425\\\"><iframe id=\\\"like_iframe_662815854023655425\\\" src=\\\"https:\\/\\/assets.tumblr.com\\/assets\\/html\\/like_iframe.html?_v=66c22ab5319d742bca5762b8d18f9d06#name=lolcats-lol-cat&amp;post_id=66281585402365\n"
     ]
    }
   ],
   "source": [
    "tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'))\n",
    "\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not look very good on first inspection, but it has far fewer angle\n",
    "braces than html, which makes it easier to parse. What we have is\n",
    "[JSON](https://en.wikipedia.org/wiki/JSON) a 'human readable' text based data\n",
    "transmission format based on javascript. Luckily, we can readily convert it to a\n",
    "python `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tumblelog', 'posts-start', 'posts-total', 'posts-type', 'posts'])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#We need to load only the stuff between the curly braces\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "print(d.keys())\n",
    "print(len(d['posts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we read the [API specification](https://www.tumblr.com/docs/en/api/v1), we\n",
    "will see there are a lot of things we can get if we add things to our GET\n",
    "request. First we can retrieve posts by their id number. Let's first get post\n",
    "`146020177084`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'), params = {'id' : 146020177084})\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "d['posts'][0].keys()\n",
    "d['posts'][0]['photo-url-1280']\n",
    "\n",
    "with open('lolcat.gif', 'wb') as f:\n",
    "    gifRequest = requests.get(d['posts'][0]['photo-url-1280'], stream = True)\n",
    "    f.write(gifRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lolcat.gif'>\n",
    "\n",
    "Such beauty; such vigor (If you can't see it you have to refresh the page). Now\n",
    "we could retrieve the text from all posts as well\n",
    "as related metadata, like the post date, caption or tags. We could also get\n",
    "links to all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>photo-url</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>photo-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>662815854023655425</td>\n",
       "      <td>https://64.media.tumblr.com/021eac8fbcafbb00a5...</td>\n",
       "      <td>Mon, 20 Sep 2021 06:00:56</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny]</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>662778109891952640</td>\n",
       "      <td>https://64.media.tumblr.com/8c0517adb8c71e4a3d...</td>\n",
       "      <td>Sun, 19 Sep 2021 20:01:00</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>662657302700146688</td>\n",
       "      <td>https://64.media.tumblr.com/061d27cda309d5c809...</td>\n",
       "      <td>Sat, 18 Sep 2021 12:00:50</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>662513901538246656</td>\n",
       "      <td>https://64.media.tumblr.com/80584a9d1ff4ddc4fc...</td>\n",
       "      <td>Thu, 16 Sep 2021 22:01:32</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662257177983090688</td>\n",
       "      <td>https://64.media.tumblr.com/893b320cd2e8970a20...</td>\n",
       "      <td>Tue, 14 Sep 2021 02:01:01</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>662166591527698432</td>\n",
       "      <td>https://64.media.tumblr.com/c7f0a0a9184e480e15...</td>\n",
       "      <td>Mon, 13 Sep 2021 02:01:11</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>662113740899090432</td>\n",
       "      <td>https://64.media.tumblr.com/07f7be7f71917a6049...</td>\n",
       "      <td>Sun, 12 Sep 2021 12:01:09</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>661955166248026112</td>\n",
       "      <td>https://64.media.tumblr.com/205f030c48d31f8960...</td>\n",
       "      <td>Fri, 10 Sep 2021 18:00:40</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>661894830378614784</td>\n",
       "      <td>https://64.media.tumblr.com/c463bff883fec2045b...</td>\n",
       "      <td>Fri, 10 Sep 2021 02:01:39</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>661864596682964992</td>\n",
       "      <td>https://64.media.tumblr.com/b840ddb3aa2303206b...</td>\n",
       "      <td>Thu, 09 Sep 2021 18:01:06</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>661826822696321024</td>\n",
       "      <td>https://64.media.tumblr.com/adc18e35b1844be41a...</td>\n",
       "      <td>Thu, 09 Sep 2021 08:00:42</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>661804260632215552</td>\n",
       "      <td>https://64.media.tumblr.com/caae5b433ada6d6cb3...</td>\n",
       "      <td>Thu, 09 Sep 2021 02:02:05</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>661766453508407296</td>\n",
       "      <td>https://64.media.tumblr.com/9d8cf92208aec32b93...</td>\n",
       "      <td>Wed, 08 Sep 2021 16:01:10</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>661623017704685568</td>\n",
       "      <td>https://64.media.tumblr.com/4a5ae6732ab54227a4...</td>\n",
       "      <td>Tue, 07 Sep 2021 02:01:19</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>661555057316298752</td>\n",
       "      <td>https://64.media.tumblr.com/c92a31829a6d88381e...</td>\n",
       "      <td>Mon, 06 Sep 2021 08:01:07</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>661509804401065984</td>\n",
       "      <td>https://64.media.tumblr.com/2653be7b6e3a8efb9e...</td>\n",
       "      <td>Sun, 05 Sep 2021 20:01:50</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>661411625970106368</td>\n",
       "      <td>https://64.media.tumblr.com/e508b4d0fcc083750b...</td>\n",
       "      <td>Sat, 04 Sep 2021 18:01:20</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>661260621178945536</td>\n",
       "      <td>https://64.media.tumblr.com/28e64b8d19014a4c98...</td>\n",
       "      <td>Fri, 03 Sep 2021 02:01:10</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>661177569862991872</td>\n",
       "      <td>https://64.media.tumblr.com/9ffadbe3e1d5fb20f8...</td>\n",
       "      <td>Thu, 02 Sep 2021 04:01:06</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>661154964805140480</td>\n",
       "      <td>https://64.media.tumblr.com/27dce173c9e6cf3f05...</td>\n",
       "      <td>Wed, 01 Sep 2021 22:01:49</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>660988818837651457</td>\n",
       "      <td>https://64.media.tumblr.com/02db958e8649c04d19...</td>\n",
       "      <td>Tue, 31 Aug 2021 02:00:59</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>660935942249578496</td>\n",
       "      <td>https://64.media.tumblr.com/80b5d0f3c5636990b9...</td>\n",
       "      <td>Mon, 30 Aug 2021 12:00:32</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>660905765646843905</td>\n",
       "      <td>https://64.media.tumblr.com/a2eb4c91986a0c1e23...</td>\n",
       "      <td>Mon, 30 Aug 2021 04:00:54</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>660898202755661824</td>\n",
       "      <td>https://64.media.tumblr.com/061d27cda309d5c809...</td>\n",
       "      <td>Mon, 30 Aug 2021 02:00:41</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>660883122996576256</td>\n",
       "      <td>https://64.media.tumblr.com/2d1137cbf0dbe21d8b...</td>\n",
       "      <td>Sun, 29 Aug 2021 22:01:00</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>660732105459924992</td>\n",
       "      <td>https://64.media.tumblr.com/cccbbc09b009b581a9...</td>\n",
       "      <td>Sat, 28 Aug 2021 06:00:38</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>660475424163364864</td>\n",
       "      <td>https://64.media.tumblr.com/9d700e79b1615fac2f...</td>\n",
       "      <td>Wed, 25 Aug 2021 10:00:48</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>660324431590277120</td>\n",
       "      <td>https://64.media.tumblr.com/7cc2c0f675bc099be4...</td>\n",
       "      <td>Mon, 23 Aug 2021 18:00:50</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>660196106964221952</td>\n",
       "      <td>https://64.media.tumblr.com/c024195387a46a6f77...</td>\n",
       "      <td>Sun, 22 Aug 2021 08:01:10</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>660143257603506176</td>\n",
       "      <td>https://64.media.tumblr.com/fdf46563a9b09ec147...</td>\n",
       "      <td>Sat, 21 Aug 2021 18:01:09</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>660060193333346304</td>\n",
       "      <td>https://64.media.tumblr.com/4183c34ae67f92f290...</td>\n",
       "      <td>Fri, 20 Aug 2021 20:00:53</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>659743087466332160</td>\n",
       "      <td>https://64.media.tumblr.com/01c63fcc1d5fc2e0e0...</td>\n",
       "      <td>Tue, 17 Aug 2021 08:00:37</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>659705393411391488</td>\n",
       "      <td>https://64.media.tumblr.com/42a1477d18728fb088...</td>\n",
       "      <td>Mon, 16 Aug 2021 22:01:30</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>659660051218317312</td>\n",
       "      <td>https://64.media.tumblr.com/a4392b133ed186fad8...</td>\n",
       "      <td>Mon, 16 Aug 2021 10:00:48</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>659539266591981568</td>\n",
       "      <td>https://64.media.tumblr.com/9024bc51ad17d40b80...</td>\n",
       "      <td>Sun, 15 Aug 2021 02:00:59</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>659509078641557504</td>\n",
       "      <td>https://64.media.tumblr.com/12afb1b79928488a1a...</td>\n",
       "      <td>Sat, 14 Aug 2021 18:01:09</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>659342999892967424</td>\n",
       "      <td>https://64.media.tumblr.com/29a90b59498d9ae55f...</td>\n",
       "      <td>Thu, 12 Aug 2021 22:01:24</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>659108907014356992</td>\n",
       "      <td>https://64.media.tumblr.com/7a11be8b9524535da2...</td>\n",
       "      <td>Tue, 10 Aug 2021 08:00:36</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>658867320238850049</td>\n",
       "      <td>https://64.media.tumblr.com/bf7efc7edad65675ad...</td>\n",
       "      <td>Sat, 07 Aug 2021 16:00:41</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>658844675622453248</td>\n",
       "      <td>https://64.media.tumblr.com/c2b58415fe3fed86a2...</td>\n",
       "      <td>Sat, 07 Aug 2021 10:00:45</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>658814510935769088</td>\n",
       "      <td>https://64.media.tumblr.com/d70155b2bdd5763cca...</td>\n",
       "      <td>Sat, 07 Aug 2021 02:01:18</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>658338845753999360</td>\n",
       "      <td>https://64.media.tumblr.com/1fca341b03f832d679...</td>\n",
       "      <td>Sun, 01 Aug 2021 20:00:48</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>658225598089609217</td>\n",
       "      <td>https://64.media.tumblr.com/07aad399cc881a2399...</td>\n",
       "      <td>Sat, 31 Jul 2021 14:00:47</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>658210575863742464</td>\n",
       "      <td>https://64.media.tumblr.com/d5b0639155ee97c854...</td>\n",
       "      <td>Sat, 31 Jul 2021 10:02:00</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>658165190497583104</td>\n",
       "      <td>https://64.media.tumblr.com/ea6ad0eae613c5f60f...</td>\n",
       "      <td>Fri, 30 Jul 2021 22:00:38</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny]</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>657946256220536832</td>\n",
       "      <td>https://64.media.tumblr.com/16cf3a5e394112f7d0...</td>\n",
       "      <td>Wed, 28 Jul 2021 12:00:46</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>657931173576704000</td>\n",
       "      <td>https://64.media.tumblr.com/2b7dfb6b1677079a45...</td>\n",
       "      <td>Wed, 28 Jul 2021 08:01:02</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>657312093673078784</td>\n",
       "      <td>https://64.media.tumblr.com/17fe9380eed8516e45...</td>\n",
       "      <td>Wed, 21 Jul 2021 12:01:01</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>656677912834195456</td>\n",
       "      <td>https://64.media.tumblr.com/7c4e668dc5eb0e89ed...</td>\n",
       "      <td>Wed, 14 Jul 2021 12:00:59</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>656647679801212928</td>\n",
       "      <td>https://64.media.tumblr.com/f411261fd1e6911697...</td>\n",
       "      <td>Wed, 14 Jul 2021 04:00:27</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          photo-url  \\\n",
       "0   662815854023655425  https://64.media.tumblr.com/021eac8fbcafbb00a5...   \n",
       "1   662778109891952640  https://64.media.tumblr.com/8c0517adb8c71e4a3d...   \n",
       "2   662657302700146688  https://64.media.tumblr.com/061d27cda309d5c809...   \n",
       "3   662513901538246656  https://64.media.tumblr.com/80584a9d1ff4ddc4fc...   \n",
       "4   662257177983090688  https://64.media.tumblr.com/893b320cd2e8970a20...   \n",
       "5   662166591527698432  https://64.media.tumblr.com/c7f0a0a9184e480e15...   \n",
       "6   662113740899090432  https://64.media.tumblr.com/07f7be7f71917a6049...   \n",
       "7   661955166248026112  https://64.media.tumblr.com/205f030c48d31f8960...   \n",
       "8   661894830378614784  https://64.media.tumblr.com/c463bff883fec2045b...   \n",
       "9   661864596682964992  https://64.media.tumblr.com/b840ddb3aa2303206b...   \n",
       "10  661826822696321024  https://64.media.tumblr.com/adc18e35b1844be41a...   \n",
       "11  661804260632215552  https://64.media.tumblr.com/caae5b433ada6d6cb3...   \n",
       "12  661766453508407296  https://64.media.tumblr.com/9d8cf92208aec32b93...   \n",
       "13  661623017704685568  https://64.media.tumblr.com/4a5ae6732ab54227a4...   \n",
       "14  661555057316298752  https://64.media.tumblr.com/c92a31829a6d88381e...   \n",
       "15  661509804401065984  https://64.media.tumblr.com/2653be7b6e3a8efb9e...   \n",
       "16  661411625970106368  https://64.media.tumblr.com/e508b4d0fcc083750b...   \n",
       "17  661260621178945536  https://64.media.tumblr.com/28e64b8d19014a4c98...   \n",
       "18  661177569862991872  https://64.media.tumblr.com/9ffadbe3e1d5fb20f8...   \n",
       "19  661154964805140480  https://64.media.tumblr.com/27dce173c9e6cf3f05...   \n",
       "20  660988818837651457  https://64.media.tumblr.com/02db958e8649c04d19...   \n",
       "21  660935942249578496  https://64.media.tumblr.com/80b5d0f3c5636990b9...   \n",
       "22  660905765646843905  https://64.media.tumblr.com/a2eb4c91986a0c1e23...   \n",
       "23  660898202755661824  https://64.media.tumblr.com/061d27cda309d5c809...   \n",
       "24  660883122996576256  https://64.media.tumblr.com/2d1137cbf0dbe21d8b...   \n",
       "25  660732105459924992  https://64.media.tumblr.com/cccbbc09b009b581a9...   \n",
       "26  660475424163364864  https://64.media.tumblr.com/9d700e79b1615fac2f...   \n",
       "27  660324431590277120  https://64.media.tumblr.com/7cc2c0f675bc099be4...   \n",
       "28  660196106964221952  https://64.media.tumblr.com/c024195387a46a6f77...   \n",
       "29  660143257603506176  https://64.media.tumblr.com/fdf46563a9b09ec147...   \n",
       "30  660060193333346304  https://64.media.tumblr.com/4183c34ae67f92f290...   \n",
       "31  659743087466332160  https://64.media.tumblr.com/01c63fcc1d5fc2e0e0...   \n",
       "32  659705393411391488  https://64.media.tumblr.com/42a1477d18728fb088...   \n",
       "33  659660051218317312  https://64.media.tumblr.com/a4392b133ed186fad8...   \n",
       "34  659539266591981568  https://64.media.tumblr.com/9024bc51ad17d40b80...   \n",
       "35  659509078641557504  https://64.media.tumblr.com/12afb1b79928488a1a...   \n",
       "36  659342999892967424  https://64.media.tumblr.com/29a90b59498d9ae55f...   \n",
       "37  659108907014356992  https://64.media.tumblr.com/7a11be8b9524535da2...   \n",
       "38  658867320238850049  https://64.media.tumblr.com/bf7efc7edad65675ad...   \n",
       "39  658844675622453248  https://64.media.tumblr.com/c2b58415fe3fed86a2...   \n",
       "40  658814510935769088  https://64.media.tumblr.com/d70155b2bdd5763cca...   \n",
       "41  658338845753999360  https://64.media.tumblr.com/1fca341b03f832d679...   \n",
       "42  658225598089609217  https://64.media.tumblr.com/07aad399cc881a2399...   \n",
       "43  658210575863742464  https://64.media.tumblr.com/d5b0639155ee97c854...   \n",
       "44  658165190497583104  https://64.media.tumblr.com/ea6ad0eae613c5f60f...   \n",
       "45  657946256220536832  https://64.media.tumblr.com/16cf3a5e394112f7d0...   \n",
       "46  657931173576704000  https://64.media.tumblr.com/2b7dfb6b1677079a45...   \n",
       "47  657312093673078784  https://64.media.tumblr.com/17fe9380eed8516e45...   \n",
       "48  656677912834195456  https://64.media.tumblr.com/7c4e668dc5eb0e89ed...   \n",
       "49  656647679801212928  https://64.media.tumblr.com/f411261fd1e6911697...   \n",
       "\n",
       "                         date                                tags photo-type  \n",
       "0   Mon, 20 Sep 2021 06:00:56  [gif, lolcat, lolcats, cat, funny]        gif  \n",
       "1   Sun, 19 Sep 2021 20:01:00   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "2   Sat, 18 Sep 2021 12:00:50   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "3   Thu, 16 Sep 2021 22:01:32   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "4   Tue, 14 Sep 2021 02:01:01   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "5   Mon, 13 Sep 2021 02:01:11   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "6   Sun, 12 Sep 2021 12:01:09   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "7   Fri, 10 Sep 2021 18:00:40   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "8   Fri, 10 Sep 2021 02:01:39   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "9   Thu, 09 Sep 2021 18:01:06   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "10  Thu, 09 Sep 2021 08:00:42   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "11  Thu, 09 Sep 2021 02:02:05   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "12  Wed, 08 Sep 2021 16:01:10   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "13  Tue, 07 Sep 2021 02:01:19   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "14  Mon, 06 Sep 2021 08:01:07   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "15  Sun, 05 Sep 2021 20:01:50   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "16  Sat, 04 Sep 2021 18:01:20   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "17  Fri, 03 Sep 2021 02:01:10   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "18  Thu, 02 Sep 2021 04:01:06   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "19  Wed, 01 Sep 2021 22:01:49   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "20  Tue, 31 Aug 2021 02:00:59   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "21  Mon, 30 Aug 2021 12:00:32   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "22  Mon, 30 Aug 2021 04:00:54   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "23  Mon, 30 Aug 2021 02:00:41   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "24  Sun, 29 Aug 2021 22:01:00   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "25  Sat, 28 Aug 2021 06:00:38   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "26  Wed, 25 Aug 2021 10:00:48   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "27  Mon, 23 Aug 2021 18:00:50   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "28  Sun, 22 Aug 2021 08:01:10   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "29  Sat, 21 Aug 2021 18:01:09   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "30  Fri, 20 Aug 2021 20:00:53   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "31  Tue, 17 Aug 2021 08:00:37   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "32  Mon, 16 Aug 2021 22:01:30   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "33  Mon, 16 Aug 2021 10:00:48   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "34  Sun, 15 Aug 2021 02:00:59   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "35  Sat, 14 Aug 2021 18:01:09   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "36  Thu, 12 Aug 2021 22:01:24   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "37  Tue, 10 Aug 2021 08:00:36   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "38  Sat, 07 Aug 2021 16:00:41   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "39  Sat, 07 Aug 2021 10:00:45   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "40  Sat, 07 Aug 2021 02:01:18   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "41  Sun, 01 Aug 2021 20:00:48   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "42  Sat, 31 Jul 2021 14:00:47   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "43  Sat, 31 Jul 2021 10:02:00   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "44  Fri, 30 Jul 2021 22:00:38  [gif, lolcat, lolcats, cat, funny]        gif  \n",
       "45  Wed, 28 Jul 2021 12:00:46   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "46  Wed, 28 Jul 2021 08:01:02   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "47  Wed, 21 Jul 2021 12:01:01   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "48  Wed, 14 Jul 2021 12:00:59   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "49  Wed, 14 Jul 2021 04:00:27   [cat, cats, lol, lolcat, lolcats]        jpg  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting a max in case the blog has millions of images\n",
    "#The given max will be rounded up to the nearest multiple of 50\n",
    "def tumblrImageScrape(blogName, maxImages = 200):\n",
    "    #Restating this here so the function isn't dependent on any external variables\n",
    "    tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "    #There are a bunch of possible locations for the photo url\n",
    "    possiblePhotoSuffixes = [1280, 500, 400, 250, 100]\n",
    "\n",
    "    #These are the pieces of information we will be gathering,\n",
    "    #at the end we will convert this to a DataFrame.\n",
    "    #There are a few other datums we could gather like the captions\n",
    "    #you can read the Tumblr documentation to learn how to get them\n",
    "    #https://www.tumblr.com/docs/en/api/v1\n",
    "    postsData = {\n",
    "        'id' : [],\n",
    "        'photo-url' : [],\n",
    "        'date' : [],\n",
    "        'tags' : [],\n",
    "        'photo-type' : []\n",
    "    }\n",
    "\n",
    "    #Tumblr limits us to a max of 50 posts per request\n",
    "    for requestNum in range(maxImages // 50):\n",
    "        requestParams = {\n",
    "            'start' : requestNum * 50,\n",
    "            'num' : 50,\n",
    "            'type' : 'photo'\n",
    "        }\n",
    "        r = requests.get(tumblrAPItarget.format(blogName), params = requestParams)\n",
    "        requestDict = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "        for postDict in requestDict['posts']:\n",
    "            #We are dealing with uncleaned data, we can't trust it.\n",
    "            #Specifically, not all posts are guaranteed to have the fields we want\n",
    "            try:\n",
    "                postsData['id'].append(postDict['id'])\n",
    "                postsData['date'].append(postDict['date'])\n",
    "                postsData['tags'].append(postDict['tags'])\n",
    "            except KeyError as e:\n",
    "                raise KeyError(\"Post {} from {} is missing: {}\".format(postDict['id'], blogName, e))\n",
    "\n",
    "            foundSuffix = False\n",
    "            for suffix in possiblePhotoSuffixes:\n",
    "                try:\n",
    "                    photoURL = postDict['photo-url-{}'.format(suffix)]\n",
    "                    postsData['photo-url'].append(photoURL)\n",
    "                    postsData['photo-type'].append(photoURL.split('.')[-1])\n",
    "                    foundSuffix = True\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if not foundSuffix:\n",
    "                #Make sure your error messages are useful\n",
    "                #You will be one of the users\n",
    "                raise KeyError(\"Post {} from {} is missing a photo url\".format(postDict['id'], blogName))\n",
    "\n",
    "    return pandas.DataFrame(postsData)\n",
    "tumblrImageScrape('lolcats-lol-cat', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the urls of a bunch of images and can run OCR on them to gather\n",
    "compelling meme narratives, accompanied by cats.\n",
    "\n",
    "# Files\n",
    "\n",
    "What if the text we want isn't on a webpage? There are a many other sources of\n",
    "text available, typically organized into *files*.\n",
    "\n",
    "## Raw text (and encoding)\n",
    "\n",
    "The most basic form of storing text is as a _raw text_ document. Source code\n",
    "(`.py`, `.r`, etc) is usually raw text as are text files (`.txt`) and those with\n",
    "many other extension (e.g., .csv, .dat, etc.). Opening an unknown file with a\n",
    "text editor is often a great way of learning what the file is.\n",
    "\n",
    "We can create a text file in python with the `open()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, mode = 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `encoding='utf-8'` argument, which specifies how we map the bits from\n",
    "the file to the glyphs (and whitespace characters like tab (`'\\t'`) or newline\n",
    "(`'\\n'`)) on the screen. When dealing only with latin letters, arabic numerals\n",
    "and the other symbols on America keyboards you usually do not have to worry\n",
    "about encodings as the ones used today are backwards compatible with\n",
    "[ASCII](https://en.wikipedia.org/wiki/ASCII), which gives the binary\n",
    "representation of 128 characters.\n",
    "\n",
    "Some of you, however, will want to use other characters (e.g., Chinese\n",
    "characters). To solve this there is\n",
    "[Unicode](https://en.wikipedia.org/wiki/Unicode) which assigns numbers to\n",
    "symbols, e.g., 041 is `'A'` and 03A3 is `'Σ'` (numbers starting with 0 are\n",
    "hexadecimal). Often non/beyond-ASCII characters are called Unicode characters.\n",
    "Unicode contains 1,114,112 characters, about 10\\% of which have been assigned.\n",
    "Unfortunately there are many ways used to map combinations of bits to Unicode\n",
    "symbols. The ones you are likely to encounter are called by Python _utf-8_,\n",
    "_utf-16_ and _latin-1_. _utf-8_ is the standard for Linux and Mac OS while both\n",
    "_utf-16_ and _latin-1_ are used by windows. If you use the wrong encoding,\n",
    "characters can appear wrong, sometimes change in number or Python could raise an\n",
    "exception. Lets see what happens when we open the file we just created with\n",
    "different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is with the correct encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\n",
      "\n",
      "This is with the wrong encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols â¡ â â  â¡ â¢ â£ àµ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with _latin-1_ the unicode characters are mixed up and there are too\n",
    "many of them. You need to keep in mind encoding when obtaining text files.\n",
    "Determining the encoding can sometime involve substantial work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load many text files at once. Lets start by looking at the Shakespeare files in the `data` directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and Train.]\n",
      "\n",
      "PUCK\n",
      "  If we shadows have offended,\n",
      "  Think but this,--and all is mended,--\n",
      "  That you have but slumber'd here\n",
      "  While these visions did appear.\n",
      "  And this weak and idle theme,\n",
      "  No more yielding but a dream,\n",
      "  Gentles, do not reprehend;\n",
      "  If you pardon, we will mend.\n",
      "  And, as I am an honest Puck,\n",
      "  If we have unearned luck\n",
      "  Now to 'scape the serpent's tongue,\n",
      "  We will make amends ere long;\n",
      "  Else the Puck a liar call:\n",
      "  So, good night unto you all.\n",
      "  Give me your hands, if we be friends,\n",
      "  And Robin shall restore amends.\n",
      "\n",
      "[Exit.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of Project Gutenberg Etext of A Midsummer Night's Dream by Shakespeare\n",
      "PG has multiple editions of William Shakespeare's Complete Works\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/Shakespeare/midsummer_nights_dream.txt') as f:\n",
    "    midsummer = f.read()\n",
    "print(midsummer[-700:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, depending on your working directory, you might get errors such as: [Errno 2] No such file or directory: '../data/Shakespeare/midsummer_nights_dream.txt.' Don't panic, it's nothing, just check your working directory. \n",
    "\n",
    "Then to load all the files in `./data/Shakespeare` we can use a for loop with `scandir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDir = '../data/Shakespeare' #Change this to your own directory of texts\n",
    "shakespearText = []\n",
    "shakespearFileName = []\n",
    "\n",
    "for file in (file for file in os.scandir(targetDir) if file.is_file() and not file.name.startswith('.')):\n",
    "    with open(file.path, encoding=\"utf-8\") as f:\n",
    "        shakespearText.append(f.read())\n",
    "    shakespearFileName.append(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can put them all in pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>julius_caesar.txt</th>\n",
       "      <td>Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as_you_like_it.txt</th>\n",
       "      <td>AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempest.txt</th>\n",
       "      <td>The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoenix_and_the_turtle.txt</th>\n",
       "      <td>THE PHOENIX AND THE TURTLE\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_lear.txt</th>\n",
       "      <td>The Tragedie of King Lear\\n\\n\\nActus Primus. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passionate_pilgrim.txt</th>\n",
       "      <td>THE PASSIONATE PILGRIM\\n\\nby William Shakespea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cymbeline.txt</th>\n",
       "      <td>The Tragedie of Cymbeline\\n\\nActus Primus. Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coriolanus.txt</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_gentlemen_of_verona.txt</th>\n",
       "      <td>THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rape_of_lucrece.txt</th>\n",
       "      <td>THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_8.txt</th>\n",
       "      <td>KING HENRY THE EIGHTH\\n\\nby William Shakespear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romeo_and_juliet.txt</th>\n",
       "      <td>ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_of_venice.txt</th>\n",
       "      <td>The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnets.txt</th>\n",
       "      <td>THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthonie_and_cleopatra.txt</th>\n",
       "      <td>The Tragedie of Anthonie, and Cleopatra\\n\\nAct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merry_wives_of_windsor.txt</th>\n",
       "      <td>THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othello.txt</th>\n",
       "      <td>THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much_ado_about_nothing.txt</th>\n",
       "      <td>MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taming_of_the_shrew.txt</th>\n",
       "      <td>THE TAMING OF THE SHREW\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winters_tale.txt</th>\n",
       "      <td>THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pericles_prince_of_tyre.txt</th>\n",
       "      <td>PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy_of_errors.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p1.txt</th>\n",
       "      <td>The First Part of Henry the Fourth\\n\\nwith the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p2.txt</th>\n",
       "      <td>KING HENRY IV, SECOND PART\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timon_of_athens.txt</th>\n",
       "      <td>THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p2.txt</th>\n",
       "      <td>The second Part of Henry the Sixt\\n\\nwith the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alls_well_that_ends_well.txt</th>\n",
       "      <td>All's Well, that Ends Well\\n\\nActus primus. Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p3.txt</th>\n",
       "      <td>The third Part of Henry the Sixt\\n\\nwith the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p1.txt</th>\n",
       "      <td>Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovers_complaint.txt</th>\n",
       "      <td>A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titus_andronicus.txt</th>\n",
       "      <td>The Tragedie of Titus Andronicus\\n\\nActus Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelth_night.txt</th>\n",
       "      <td>TWELFTH NIGHT;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves_labors_lost.txt</th>\n",
       "      <td>LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midsummer_nights_dream.txt</th>\n",
       "      <td>A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_5.txt</th>\n",
       "      <td>THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_john.txt</th>\n",
       "      <td>The life and death of King John\\n\\nActus Primu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macbeth.txt</th>\n",
       "      <td>MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troilus_and_cressida.txt</th>\n",
       "      <td>THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus_and_adonis.txt</th>\n",
       "      <td>VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_for_measure.txt</th>\n",
       "      <td>MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamlet.txt</th>\n",
       "      <td>The Tragedie of Hamlet\\n\\nActus Primus. Scoena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_2.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_3.txt</th>\n",
       "      <td>KING RICHARD III\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           text\n",
       "julius_caesar.txt             Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...\n",
       "as_you_like_it.txt            AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...\n",
       "tempest.txt                   The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...\n",
       "phoenix_and_the_turtle.txt    THE PHOENIX AND THE TURTLE\\n\\nby William Shake...\n",
       "king_lear.txt                 The Tragedie of King Lear\\n\\n\\nActus Primus. S...\n",
       "passionate_pilgrim.txt        THE PASSIONATE PILGRIM\\n\\nby William Shakespea...\n",
       "cymbeline.txt                 The Tragedie of Cymbeline\\n\\nActus Primus. Sco...\n",
       "coriolanus.txt                THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...\n",
       "two_gentlemen_of_verona.txt   THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...\n",
       "rape_of_lucrece.txt           THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...\n",
       "king_henry_8.txt              KING HENRY THE EIGHTH\\n\\nby William Shakespear...\n",
       "romeo_and_juliet.txt          ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...\n",
       "merchant_of_venice.txt        The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...\n",
       "sonnets.txt                   THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...\n",
       "anthonie_and_cleopatra.txt    The Tragedie of Anthonie, and Cleopatra\\n\\nAct...\n",
       "merry_wives_of_windsor.txt    THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...\n",
       "othello.txt                   THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...\n",
       "much_ado_about_nothing.txt    MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...\n",
       "taming_of_the_shrew.txt       THE TAMING OF THE SHREW\\n\\nby William Shakespe...\n",
       "winters_tale.txt              THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...\n",
       "pericles_prince_of_tyre.txt   PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...\n",
       "comedy_of_errors.txt          DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...\n",
       "king_henry_4_p1.txt           The First Part of Henry the Fourth\\n\\nwith the...\n",
       "king_henry_4_p2.txt           KING HENRY IV, SECOND PART\\n\\nby William Shake...\n",
       "timon_of_athens.txt           THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...\n",
       "king_henry_6_p2.txt           The second Part of Henry the Sixt\\n\\nwith the ...\n",
       "alls_well_that_ends_well.txt  All's Well, that Ends Well\\n\\nActus primus. Sc...\n",
       "king_henry_6_p3.txt           The third Part of Henry the Sixt\\n\\nwith the d...\n",
       "king_henry_6_p1.txt           Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...\n",
       "lovers_complaint.txt          A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...\n",
       "titus_andronicus.txt          The Tragedie of Titus Andronicus\\n\\nActus Prim...\n",
       "twelth_night.txt                                           TWELFTH NIGHT;\\n ...\n",
       "loves_labors_lost.txt         LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...\n",
       "midsummer_nights_dream.txt    A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...\n",
       "king_henry_5.txt              THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...\n",
       "king_john.txt                 The life and death of King John\\n\\nActus Primu...\n",
       "macbeth.txt                   MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...\n",
       "troilus_and_cressida.txt      THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...\n",
       "venus_and_adonis.txt          VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...\n",
       "measure_for_measure.txt       MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...\n",
       "hamlet.txt                    The Tragedie of Hamlet\\n\\nActus Primus. Scoena...\n",
       "king_richard_2.txt            DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...\n",
       "king_richard_3.txt            KING RICHARD III\\n\\nby William Shakespeare\\n\\n..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_df = pandas.DataFrame({'text' : shakespearText}, index = shakespearFileName)\n",
    "shakespear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting your text in a format like this is the first step of most analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "Another common way text will be stored is in a PDF file. First we will download\n",
    "a pdf in Python. To do that lets grab a chapter from\n",
    "_Speech and Language Processing_, chapter 21 is on Information Extraction which\n",
    "seems apt. It is stored as a pdf at [https://web.stanford.edu/~jurafsky/slp3/21.\n",
    "pdf](https://web.stanford.edu/~jurafsky/slp3/21.pdf) although we are downloading\n",
    "from a copy just in case Jurafsky changes their website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.3\n",
      "%���������\n",
      "4 0 obj\n",
      "<< /Length 5 0 R /Filter /FlateDecode >>\n",
      "stream\n",
      "x\u0001�]۶�F�}�W�c����T���\u0017C\u000f�i�\u0019<t\u001f�b\u0001\u000fM�f\n",
      "Tn�\u0006<3_�\u000b",
      "�CDf�\u001d",
      "�J�N�i�\u000f�#�%.;.\u0019���\t?\u000f߄��7�]8������ux��}\u001b޾\u000fm����y��bǾ���\u0010�!\u001c",
      "\u000e���$�Ǯ���C�\u0007�F\u0006�����p�\u000f��5��1��1�P<�{�\u0010$�\u001a�/$�P�\f",
      "s�v��P\u001e",
      "gH?�����Q�~�*�:l��ˇ�m�ǰ��C�l����܊\u0017��E��\u001e",
      "���\u000f!�^�y��\u001am�$�Ý���wۡل׼�6w���ī�K�~؞���r��\u0010~\u001b\u001e",
      "?�ˡkO�;6IH�9{ԡ���\u0000]?�E�E�\u0012�~���.l������+��\u001c",
      "W�\u000e\u0002_�\u000e��\u0002\u0002��C��S�|�~\u0005C��N�3ӛB`8�ޚ\b\u0001j9���AZ�\u0004�\u00110�d�l^�\u000e�����SY\u0012\t�Ƨ��>\u000b",
      "q�ۇ&\n",
      "����.�����0���\u0015�;\u0000��>a8�$\f",
      "w�p��p����ST���\u000b",
      ".\u0000�7��@�\u0012���)�\u0013�&1�|���\u0002\u0004WՃ jOv�G2b�L8I��N�@\u0001\u001e",
      "gǍ�\u0004����\u0019�O�C��������IN@@���\u0002��\u0013}�8��+L����a�\u0005&ү\b�o\u0005\u0013�V(\u0019���0\f",
      "���+5\u001b�\n",
      "S\u001d",
      "fS&��<�2���\u001e",
      "��>l�V��&��=4⇤\u0019=\u001a�W��<�J\u0013Mo�\u001c",
      "���\"����d�C����[vY�|K\u001c",
      "{_ܔ\\��\u0017��%\u0001H�/@'�QA�+D�l��c��L�G�.��\t�̎�V�:f>���Aw\u0010K���o$`D\u0007��\u000b",
      "bE45�\u000b",
      "0\b�\u0015%th6h��\u0005���>*�2vQd\u0010\u0015�+M��Y}�Q���u�[���N�o'b\u0010��/u�.r'Z�\u0017��J�\u0019e8�v\u0013\u000b",
      "��;�\u001d",
      "�{T�\t\f",
      "�����^8�\u0014 \u001a\u0018 l<�E�<���b�����C8\f",
      "j��f��xB>\u0001K\u0010���\u0019��|\u001f\u0004w��f�|?�\u0001s̭\u0018��Y�'�Ip&�\"�\u000b",
      "A���f�?�\b!IYi���U�\"��y;�\u0007��#�\u000b",
      "\u000f�e3)�+B�&���\u001d",
      "�<\bE9I�g�/]\"D��yfC;e����Y^�z ��s'�)/�X�-HY��<ˬ�ݰ\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://github.com/KnowledgeLab/content_analysis/raw/data/21.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf, stream=True)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It says `'pdf'`, so thats a good sign. The rest though looks like we are having\n",
    "issues with an encoding. The random characters are not caused by our encoding\n",
    "being wrong, however. They are cause by there not being an encoding for those\n",
    "parts at all. PDFs are nominally binary files, meaning there are sections of\n",
    "binary that are specific to pdf and nothing else so you need something that\n",
    "knows about pdf to read them. To do that we will be using\n",
    "[`PyPDF2`](https://github.com/mstamy2/PyPDF2), a PDF processing library for\n",
    "Python 3.\n",
    "\n",
    "\n",
    "Because PDFs are a very complicated file format pdfminer requires a large amount\n",
    "of boilerplate code to extract text, we have written a function that takes in an\n",
    "open PDF file and returns the text so you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(pdfFile):\n",
    "    #Based on code from http://stackoverflow.com/a/20905381/4955164\n",
    "    #Using utf-8, if there are a bunch of random symbols try changing this\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #We need a device and an interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to take the response object and convert it into a 'file like'\n",
    "object so that pdfminer can read it. To do this we will use `io`'s `BytesIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoExtractionBytes = io.BytesIO(infoExtractionRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can give it to pdfminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department of  Sociology \n",
      "\n",
      "THE UNIVERSITY OF CHICAGO \n",
      "\n",
      "SOCIOLOGY 40133 \n",
      "\n",
      "Computational Content Analysis \n",
      "\n",
      "Friday 1:00 – 3:50pm \n",
      "Winter 2017-2018 \n",
      "Classroom: Harper Memorial 130       \n",
      "http://chalk.uchicago.edu/ \n",
      "\n",
      " \n",
      "\n",
      "                                                                                           \n",
      "\n",
      "          Office: McGiffert 210 \n",
      "                                                    Tel.: 834-3612; jevans@uchicago.edu \n",
      "                                  Office Hours: Thursday 12:30-2:30pm \n",
      "\n",
      "     \n",
      "\n",
      "        James A. Evans            \n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(readPDF(infoExtractionBytes)[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can either look at the full text or fiddle with our PDF reader and\n",
    "get more information about individual blocks of text.\n",
    "\n",
    "## Word Docs\n",
    "\n",
    "The other type of document you are likely to encounter is the `.docx`, these are\n",
    "actually a version of [XML](https://en.wikipedia.org/wiki/Office_Open_XML), just\n",
    "like HTML, and like HTML we will use a specialized parser.\n",
    "\n",
    "For this class we will use [`python-docx`](https://python-\n",
    "docx.readthedocs.io/en/latest/) which provides a nice simple interface for\n",
    "reading `.docx` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "#example_docx = 'https://github.com/KnowledgeLab/content_analysis/raw/data/example_doc.docx'\n",
    "\n",
    "r = requests.get(example_docx, stream=True)\n",
    "d = docx.Document(io.BytesIO(r.content))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure uses the `io.BytesIO` class again, since `docx.Document` expects\n",
    "a file. Another way to do it is to save the document to a file and then read it\n",
    "like any other file. If we do this we can either delete the file afterwords, or\n",
    "save it and avoid downloading the following time.\n",
    "\n",
    "This function is useful as a part of many different tasks so it and others like it will be added to the helper package `lucem_illud` so we can use it later without having to retype it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadIfNeeded(targetURL, outputFile, **openkwargs):\n",
    "    if not os.path.isfile(outputFile):\n",
    "        outputDir = os.path.dirname(outputFile)\n",
    "        #This function is a more general os.mkdir()\n",
    "        if len(outputDir) > 0:\n",
    "            os.makedirs(outputDir, exist_ok = True)\n",
    "        r = requests.get(targetURL, stream=True)\n",
    "        #Using a closure like this is generally better than having to\n",
    "        #remember to close the file. There are ways to make this function\n",
    "        #work as a closure too\n",
    "        with open(outputFile, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    return open(outputFile, **openkwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download, save and open `outputFile` as `outputFile` or just\n",
    "open it if `outputFile` exists. By default `open()` will open the file as read\n",
    "only text with the local encoding, which may cause issues if its not a text\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d = docx.Document(downloadIfNeeded(example_docx, example_docx_save))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell `open()` to read in binary mode (`'rb'`), this is why we added\n",
    "`**openkwargs`, this allows us to pass any keyword arguments (kwargs) from\n",
    "`downloadIfNeeded` to `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "d = docx.Document(downloadIfNeeded(example_docx, example_docx_save, mode = 'rb'))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the file with `docx.Document` and not have to wait for it to be\n",
    "downloaded every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 3</font>\n",
    "<font color=\"red\">Construct cells immediately below this that extract and organize textual content from text, PDF or Word into a pandas dataframe.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfurl = 'https://dl.acm.org/doi/pdf/10.1145/2187836.2187931?casa_token=38JurJdWVWwAAAAA:u-6cj2VBVHdDef5xPQHHbmhMcZSPNeP2jFeklzOcqgdlj_zfeNebyNDM90JGZr-LtjDKCVqN61iy8A'\n",
    "pdfrequest = requests.get(pdfurl, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echoes of Power: Language Effects and Power Differences\n",
      "\n",
      "in Social Interaction\n",
      "\n",
      "Cristian Danescu-Niculescu-Mizil\n",
      "\n",
      "Cornell University\n",
      "\n",
      "cristian@cs.cornell.edu,\n",
      "\n",
      "llee@cs.cornell.edu,\n",
      "\n",
      "bopang@yahoo-inc.com,\n",
      "\n",
      "Lillian Lee\n",
      "\n",
      "Cornell University\n",
      "\n",
      "Bo Pang\n",
      "Yahoo!\n",
      "\n",
      "Jon Kleinberg\n",
      "Cornell University\n",
      "kleinber@cs.cornell.edu\n",
      "\n",
      "ABSTRACT\n",
      "Understanding social interaction within groups is key to analyz-\n",
      "ing online communities. Most current work focuses on structural\n",
      "properties: who talks to whom, and how such interactions form\n",
      "larger network structures. The interactions themselves, however,\n",
      "generally take place in the form of natural language — either spo-\n",
      "ken or written — and one could reasonably suppose that signals\n",
      "manifested in language might also provide information about roles,\n",
      "status, and other aspects of the group’s dynamics. To date, how-\n",
      "ever, ﬁnding domain-independent language-based signals has been\n",
      "a challenge.\n",
      "\n",
      "Here, we show that in group discussions, power differentials be-\n",
      "tween participants are subtly revealed by how much one individual\n",
      "immediately echoes the linguistic style of the person they are re-\n",
      "sponding to. Starting from this observation, we propose an anal-\n",
      "ysis framework based on linguistic coordination that can be used\n",
      "to shed light on power relationships and that works consistently\n",
      "across multiple types of power — including a more “static” form\n",
      "of power based on status differences, and a more “situational” form\n",
      "of power in which one individual experiences a type of dependence\n",
      "on another. Using this framework, we study how conversational\n",
      "behavior can reveal power relationships in two very different set-\n",
      "tings: discussions among Wikipedians and arguments before the\n",
      "U. S. Supreme Court.\n",
      "Categories and Subject Descriptors: J.4 [Computer Applica-\n",
      "tions]: Social and behavioral sciences\n",
      "General Terms: Measurement, Experimentation\n",
      "Keywords power, relations, dependence, social status, linguistic\n",
      "style, coordination, linguistic convergence, language, online com-\n",
      "munities, dependence, accommodation\n",
      "\n",
      "1.\n",
      "\n",
      "INTRODUCTION\n",
      "\n",
      "With the arrival of detailed data on the interactions within social\n",
      "groups — generally coming from the on-line domain — an active\n",
      "line of research has developed around the phenomena taking place\n",
      "in these groups. To date, these analyses have mainly used structural\n",
      "features of the interactions, including who talks to whom, how fre-\n",
      "quently, and how these patterns of interaction form larger network\n",
      "structures.\n",
      "\n",
      "But the interactions themselves are generally taking place in nat-\n",
      "ural language — both spoken and written — and the language con-\n",
      "\n",
      "Copyright is held by the International World Wide Web Conference Com-\n",
      "mittee (IW3C2). Distribution of these papers is limited to classroom use,\n",
      "and personal use by others.\n",
      "WWW 2012, April 16–20, 2012, Lyon, France.\n",
      "ACM 978-1-4503-1229-5/12/04.\n",
      "\n",
      "tent of these interactions has been a long-acknowledged missing\n",
      "ingredient in this style of investigation. The reason for this is clear:\n",
      "while it is reasonable to suppose that signals within the language\n",
      "could provide insight into the social structure of the group, it has\n",
      "been challenging to extract useful language-level signals. A small\n",
      "but growing line of work has begun to use textual content for un-\n",
      "covering structural properties of on-line networks [5, 9, 12, 13, 18,\n",
      "19, 35, 40, 54]; it is exciting to contemplate extending the range of\n",
      "social properties that can be analyzed via text.\n",
      "\n",
      "Power and linguistic style. In this paper, we show how variations\n",
      "in linguistic style can provide information about power differences\n",
      "within social groups. Our focus is on domains in which groups en-\n",
      "gage in goal-oriented discussions — situations where people inter-\n",
      "act, not necessarily collaboratively, in order to accomplish tasks or\n",
      "settle on choices. An important characteristic of such discussions is\n",
      "that the participants are invested in the issues at hand, so that their\n",
      "dialogs are not simply “idle chat”, but consequential: the outcome\n",
      "matters. Examples include conversations among wiki editors or\n",
      "open-source teams regarding modiﬁcations; debates within confer-\n",
      "ence program committees on which papers to accept; and discus-\n",
      "sions in legal hearings, where opposing sides compete to persuade\n",
      "a judge or jury.\n",
      "\n",
      "Power differences among the participants constitute a crucial\n",
      "force in all these settings. Sometimes these power differences are\n",
      "embodied in formal roles, such as that of a judge or a program chair.\n",
      "Sometimes they are based on more informal differences in the re-\n",
      "spect or authority commanded by individuals within the group.\n",
      "And sometimes they are more situational: x may have power over\n",
      "y in a given situation because y needs something that x can choose\n",
      "to provide or not.\n",
      "\n",
      "It is natural to ask how we might try to create widely-applicable\n",
      "methods for inferring these power differences simply by observa-\n",
      "tion of the language used within a group. This is particularly chal-\n",
      "lenging if we are seeking methods that generalize across domains,\n",
      "and are not tied to speciﬁc choices of content. By way of analogy,\n",
      "imagine that you walk into a meeting among people you’ve never\n",
      "met, and on a topic that you know nothing about; what could you\n",
      "do to identify who are the most powerful members of the group? If\n",
      "you were actually able to observe the people and hear them speak-\n",
      "ing to each other, then cues such as posture and vocal pitch can\n",
      "provide such information [20, 27]. But if we only have the text or\n",
      "transcripts of their interactions — the formats that online data often\n",
      "takes — how do we identify evidence of power differences?\n",
      "\n",
      "Language coordination. We propose that language coordination\n",
      "in text content alone can serve as a rich source of information about\n",
      "power differences within a group. Language coordination is a phe-\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France699\f",
      "nomenon in which people tend to unconsciously mimic the choices\n",
      "of function-word classes made by the people they are communi-\n",
      "cating with [39]; roughly speaking, if you are communicating with\n",
      "someone who uses a lot of articles — or prepositions, or personal\n",
      "pronouns — then you will tend to increase your usage of these\n",
      "types of words as well, even if you don’t consciously realize it.1\n",
      "\n",
      "We measure language coordination in two datasets of goal-oriented\n",
      "text that arise in very different settings: discussions among Wikipedia\n",
      "editors, containing over 240,000 conversational exchanges; and oral\n",
      "arguments before the U.S. Supreme Court, as processed by Hawes\n",
      "et al.\n",
      "[24, 25] and containing 50,389 conversational exchanges\n",
      "among Justices and lawyers. By focusing on function word classes,\n",
      "rather than domain-speciﬁc substantive content, we are able to eval-\n",
      "uate the domain-independence of our techniques and their ability to\n",
      "generalize across different contexts; methods that rely on subject-\n",
      "speciﬁc cues to determine levels of power (such as the use of “Your\n",
      "honor” in a legal setting) are not positioned to generalize as readily.\n",
      "To be able to speak in a principled way about power differences,\n",
      "we draw on the framework of exchange theory from sociology [51].\n",
      "Exchange theory and its generalizations [49] have distinguished be-\n",
      "tween two forms of power, which naturally parallel the types of\n",
      "power in our discussion above. First, a power difference between\n",
      "x and y can be based on the fact that x has higher status than y, ei-\n",
      "ther through a formal designation of status, or through more infor-\n",
      "mal notions of status based on reputation within the group. Second,\n",
      "a power difference can also arise through dependence: if y needs\n",
      "something from x, and hence is dependent on x, this can give x a\n",
      "form of at least temporary power over y.\n",
      "\n",
      "Power differences from language coordination. We ﬁnd that dif-\n",
      "ferences in the level of language coordination consistently reveal\n",
      "both of these types of power differences, in both of our datasets.\n",
      "Speciﬁcally, we will present the following results.\n",
      "\n",
      "1. In general, people with low power exhibit greater language\n",
      "\n",
      "coordination than people with high power.\n",
      "\n",
      "2. Conversely, people coordinate more with interlocutors who\n",
      "\n",
      "have higher power than with those who have lower power.\n",
      "\n",
      "3. When a person undergoes a change in status, their coordina-\n",
      "tion behavior changes, and so does the coordination behavior\n",
      "of people talking to them.\n",
      "\n",
      "4. When an individual is trying to convince someone who holds\n",
      "an opposing view, this creates a form of dependence and\n",
      "hence a power deﬁcit in the sense of exchange theory; we\n",
      "ﬁnd increased levels of language coordination in such cases.\n",
      "\n",
      "5. The relation between status level and the extent of language\n",
      "coordination transfers across domains, and is a reliable cross-\n",
      "domain feature for status prediction.\n",
      "\n",
      "These results suggest clear potential applications to the analysis\n",
      "of on-line social groups. In particular, they could provide meth-\n",
      "ods for identifying power differences and levels of status in on-line\n",
      "settings where one has only the text content of social interactions,\n",
      "rather than explicit markers of status or explicitly annotated links.\n",
      "Similarly, they could also provide a means of analyzing conversa-\n",
      "tions between users of a social media platform so as to determine\n",
      "the power balance or levels of relative status in their relationship.\n",
      "\n",
      "1We note that language coordination is just one form of coordina-\n",
      "tion where such phenomena occur [21] (another is posture coordi-\n",
      "nation, for example); we focus on language coordination because it\n",
      "can be measured in textual interactions.\n",
      "\n",
      "In all such uses, the methods do not require domain-speciﬁc knowl-\n",
      "edge of the on-line application being analyzed. We also note that\n",
      "the role of features internal to the content can be crucial in some of\n",
      "these settings, since it has been observed that message frequency\n",
      "and message volume do not necessarily sufﬁce to determine relative\n",
      "status. As Rowe et al. state [42], “As we move down the corporate\n",
      "ladder, the conversational ﬂows of dissimilar employees can in fact\n",
      "be quite similar.” Indeed, it is easy to think of contexts where dom-\n",
      "inant individuals consume a lot of the conversational bandwidth,\n",
      "and others where, contrariwise, low-status individual take up most\n",
      "of the airtime with their advocacy toward higher-status participants.\n",
      "There is something striking about the fact that the content fea-\n",
      "tures being employed are properties of language that tend to escape\n",
      "conscious attention. The phenomena we ﬁnd in the text content are\n",
      "consistent and signiﬁcant, but they are not effects one notices in\n",
      "reading or listening to the interactions; in essence, they operate on\n",
      "levels that only show up when you use computational methods to\n",
      "explicitly tune in to them. Moreover, since our methods are based\n",
      "on function words, it means one can apply them to language sam-\n",
      "ples from which the content words have been redacted, raising in-\n",
      "triguing implications for compact representations and user privacy.\n",
      "\n",
      "Summary: Novel contributions of present work. Our use of lan-\n",
      "guage coordination as a key source of information draws on a his-\n",
      "tory of coordination studies originating in social psychology; we\n",
      "discuss this background in §2. These psychological studies of co-\n",
      "ordination focused on small-scale settings where participant behav-\n",
      "iors could be individually observed; the identiﬁcation of language\n",
      "coordination phenomena in large-scale on-line text was done re-\n",
      "cently by [10] using data from Twitter. To our knowledge, our work\n",
      "is the ﬁrst to identify connections between language coordination\n",
      "and social power relations at large scales, and across a diverse set\n",
      "of individuals and domains.\n",
      "\n",
      "In addition, our work here provides the following further novel\n",
      "\n",
      "contributions.\n",
      "\n",
      "Multiple domains with large amounts of data. By using large\n",
      "amounts of data, we can pick up subtle effects and explicitly vary\n",
      "some of the underlying conditions for coordination across differ-\n",
      "ent subsets of the data. Moreover, working with two different cor-\n",
      "pora allows us to test the domain independence of our linguistic-\n",
      "coordination approach.\n",
      "\n",
      "Status change. Wikipedians can be promoted to administrator\n",
      "status through a public election, and almost always after extensive\n",
      "prior involvement in the community. Since we track the communi-\n",
      "cations of editors over time, we can examine how linguistic coordi-\n",
      "nation behavior changes when a Wikipedian becomes an “admin”.\n",
      "To our knowledge, our study is the ﬁrst to analyze the effects of\n",
      "status change on speciﬁc forms of language use.\n",
      "\n",
      "Situation-dependent forms of power. By generalizing from status\n",
      "to broader notions of power, our study is, to our knowledge, also\n",
      "the ﬁrst to show how multiple types of power relationships — and\n",
      "in particular situation-dependent power — can be exposed through\n",
      "domain-independent textual features.\n",
      "\n",
      "2. COORDINATION AND POWER\n",
      "\n",
      "We can apply communication accommodation theory [20, 21,\n",
      "38, 45], an inﬂuential line of research in sociolinguistics, to our\n",
      "investigations because the theory implies the following principle:\n",
      "Principle P. Linguistic coordination is a function of the power\n",
      "differential between the speaker and the target: the lower the\n",
      "power of the speaker relative to that of the target, the more\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France700\f",
      "she coordinates (and vice versa, the higher the relative power\n",
      "of the speaker, the less she coordinates).\n",
      "\n",
      "Here and throughout, speaker refers to the person producing the\n",
      "reply in an exchange, and target refers to the person initiating the\n",
      "exchange (and thus the target of the speaker’s reply). 2 In the con-\n",
      "text of group conversations, which is the focus of the present work,\n",
      "this principle leads to the following two concrete hypotheses, based\n",
      "on the power of the target and of the speaker, respectively:\n",
      "Ptarget: People in general coordinate more towards high-powered\n",
      "\n",
      "people than towards low-powered people.\n",
      "\n",
      "Pspeaker: High-powered people coordinate less than low-powered\n",
      "\n",
      "people towards their targets.\n",
      "\n",
      "(Neither hypothesis implies the other because we employ an asym-\n",
      "metric deﬁnition of coordination.)\n",
      "\n",
      "In addition to power imbalance, we hypothesize that personal\n",
      "traits of the participants also inﬂuence how much they coordinate:\n",
      "B. People have a baseline coordination level, which is determined\n",
      "by personal characteristics (such as their sociability and level\n",
      "of social engagement).\n",
      "\n",
      "It is worth noting that it is not actually a priori obvious that\n",
      "Ptarget and Pspeaker hold at large. First, there are competing the-\n",
      "ories which postulate that the relation between power and coordi-\n",
      "nation is the reverse of P, due to a desire of high-status individuals\n",
      "to be understood [2]. Second, empirical studies supporting the hy-\n",
      "potheses above are, while intriguing, relatively small in scale. For\n",
      "example, [22] showed that Larry King, the host of a popular talk-\n",
      "show in the U. S., coordinated more in his vocal pitch to his high-\n",
      "status guests (such as then-President Clinton) than to low-status\n",
      "guests. As for linguistic style coordination, [39] looked at 15 Wa-\n",
      "tergate transcripts involving only four people altogether (Richard\n",
      "Nixon and three of his aides); small numbers of courtroom trials\n",
      "have also been considered [1, 15].\n",
      "While power might correlate with certain personal traits in a\n",
      "given community, making the distinction between P and B difﬁ-\n",
      "cult, they differ in one important aspect which we will exploit in\n",
      "our study: power can change abruptly — such as when an indi-\n",
      "vidual is assigned a new role — while personal traits, in compar-\n",
      "ison, are more stable over time. As a result, examining the tem-\n",
      "poral change in coordination level of people who have undergone\n",
      "changes in power can help us isolate the effect of P from that of\n",
      "B. In particular, this will help us address the following question: if\n",
      "we do ﬁnd evidence supporting hypothesis B, would it be sufﬁcient\n",
      "to explain the data, or will we see power playing a role on top of\n",
      "baseline individual coordination levels?\n",
      "\n",
      "3. POWER RELATIONS IN WIKIPEDIA AND\n",
      "\n",
      "SUPREME COURT DATA\n",
      "\n",
      "In this section, we describe the two corpora of consequential dis-\n",
      "cussions we used in our studies. The ﬁrst consists of discussions\n",
      "between editors on Wikipedia; the second consists of transcripts\n",
      "of oral arguments before the United States Supreme Court. Both\n",
      "settings involve power differentials, both through status and de-\n",
      "pendence, as we will see below. Our Wikipedia corpus is much\n",
      "larger, potentially more representative of online discussions, and\n",
      "allows us to study the effects of changes in power; but the Supreme\n",
      "\n",
      "Court represents a less collaborative situation than Wikipedia (in\n",
      "the Supreme Court data, there are always explicit opposing sides)\n",
      "and is an instance of an off-line setting. The differences in the\n",
      "two corpora help us focus on general, domain-independent rela-\n",
      "tionships between relative power and linguistic coordination.\n",
      "\n",
      "We begin by brieﬂy describing the roles and text content of our\n",
      "two domains, and then discuss how we formalize the different kinds\n",
      "of power imbalances within the domains.\n",
      "\n",
      "We will release our data publicly at http://www.cs.cornell.edu/\n",
      "\n",
      "~cristian/www2012/.\n",
      "3.1 Discussions among Wikipedia editors\n",
      "Roles and role changes. Wikipedia editors form a close com-\n",
      "munity with salient markers of status. Administrators, commonly\n",
      "known as admins, are Wikipedia editors “trusted with access to re-\n",
      "stricted technical features” such as protecting or deleting pages or\n",
      "blocking other editors3. In effect, admins have a higher status than\n",
      "other users (non-admins) in the Wikipedia community, and editors\n",
      "seem to be well aware of the status and activity history of other ed-\n",
      "itors. Users are promoted to admins through a transparent election\n",
      "process known as requests for adminship4, or RfAs, where the com-\n",
      "munity decides who will become admins. Since RfAs are well doc-\n",
      "umented and timestamped, not only do we have the current status of\n",
      "editors, we can also extract the exact time when editors underwent\n",
      "role changes from non-admins to admins.\n",
      "Textual exchanges. Editors on Wikipedia interact on talk pages5\n",
      "to discuss changes to article or project pages. We gathered 240,436\n",
      "conversational exchanges carried out on the talk pages, where the\n",
      "participants of these (asynchronous) discussions were associated\n",
      "with rich status and social interaction information: status, times-\n",
      "tamp of status change if there is one, and activity level on talk\n",
      "pages, which can serve as a proxy of editors’ sociability, or how\n",
      "socially inclined they are. In addition, there is a discussion phase\n",
      "during RfAs, where users “give their opinions, ask questions, and\n",
      "make comments” about an open nomination. Candidates can reply\n",
      "to existing posts during this time. We extracted conversations that\n",
      "occurred in RfA discussions, and obtained a total of 32,000 conver-\n",
      "sational exchanges. Most of our experiments were carried out on\n",
      "the larger dataset extracted from talk pages, unless otherwise noted.\n",
      "3.2 Supreme Court oral arguments\n",
      "\n",
      "While Wikipedia discussions provide a large-scale dataset with\n",
      "rich meta-information, overall, high-status people and low-status\n",
      "people are collaborating to accomplish a task. Other social hierar-\n",
      "chies involve much less collaboration or even explicitly adversarial\n",
      "relationships. Oral arguments before the Supreme Court provide\n",
      "such a setting.\n",
      "Roles. A full court consists of nine Justices, although occasionally\n",
      "some recuse themselves. In the oral arguments for a case, lawyers\n",
      "for each party have thirty minutes to present their side to the Jus-\n",
      "tices. The Justices may interrupt these presentations with com-\n",
      "ments or questions, leading to interactions between the lawyers\n",
      "(plus amici curiae, who for our status-based investigations count\n",
      "as lawyers) and Justices. After the oral arguments and subsequent\n",
      "deliberations, cases are decided by majority vote of the Justices.\n",
      "This provides an interesting additional test ground: instead of asyn-\n",
      "chronous textual exchanges in a social hierarchy working collabo-\n",
      "ratively, here we have verbal exchanges in a social hierarchy where\n",
      "\n",
      "2We use “initiate” and “reply” loosely: in our terminology, the con-\n",
      "versation (cid:104)x: “Hi.” y: “Tired?” x: “No.”(cid:105) has two exchanges, one\n",
      "initiated by x’s “Hi”, the other by y’s “Tired?”.\n",
      "\n",
      "3http://en.wikipedia.org/wiki/Wikipedia:Administrators\n",
      "4http://en.wikipedia.org/wiki/Wikipedia:Requests_for_adminship\n",
      "5http://en.wikipedia.org/wiki/Wikipedia:Talk_page_guidelines\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France701\f",
      "higher power\n",
      "\n",
      "admins\n",
      "admins\n",
      "diff. vote\n",
      "\n",
      "Status\n",
      "\n",
      "Dependence\n",
      "\n",
      "Wikipedia\n",
      "\n",
      "admins-to-be (before RfAs)\n",
      "\n",
      "lower power\n",
      "non-admins\n",
      "\n",
      "same vote\n",
      "\n",
      "Supreme Court\n",
      "\n",
      "higher power\n",
      "\n",
      "lower power\n",
      "\n",
      "Status\n",
      "\n",
      "Justices\n",
      "\n",
      "Chief Justices\n",
      "\n",
      "Dependence\n",
      "\n",
      "unfavorable Justice\n",
      "\n",
      "lawyers\n",
      "\n",
      "Associate Justices\n",
      "favorable Justice\n",
      "\n",
      "Table 1: Power differentials exhibited in our data.\n",
      "\n",
      "Justices decide the ﬁnal outcome. In addition, conversations here\n",
      "are over topics in a completely different domain.\n",
      "Transcripts of verbal exchanges. Transcripts of oral arguments\n",
      "in Supreme Court are publicly available6. We used a pre-processed\n",
      "version of this dataset described in [24]. We enhanced this dataset\n",
      "with the ﬁnal votes from the Spaeth Supreme Court database7. In\n",
      "total, we have 50,389 verbal exchanges for 204 cases. 11 justices\n",
      "(two of which have little conversational data: Thomas8 and Al-\n",
      "ito) and 311 lawyers are represented in the dataset. 73% of the\n",
      "lawyers only appear in one case, and the maximum number of cases\n",
      "where one lawyer appears is 15. As such, trends identiﬁed on this\n",
      "dataset should not be due to idiosyncratic behavior of a few over-\n",
      "represented lawyers.\n",
      "3.3 Power Relations in the Data\n",
      "\n",
      "Having now surveyed the nature of the two domains, we dis-\n",
      "cuss the different kinds of power relations that they contain. An\n",
      "overview of the following discussion is summarized in Table 1.9\n",
      "\n",
      "In our discussion of roles earlier in this section, we have already\n",
      "indicated some of the basic status differences: the distinction be-\n",
      "tween admins and non-admins on Wikipedia, and the distinction\n",
      "between Justices and lawyers in the context of the Supreme Court.\n",
      "We can also identify certain ﬁner-grained distinctions, including\n",
      "the distinction between the Chief Justice of the Supreme Court (our\n",
      "data overlaps the terms of two different Chief Justices) and the As-\n",
      "sociate Justices. And on Wikipedia, we can also study the behavior\n",
      "over time of users who were promoted to the position of admin —\n",
      "in effect, comparing their behavior as admins to their earlier behav-\n",
      "ior as admins-to-be.\n",
      "\n",
      "Our data also makes it possible to study several instances of\n",
      "power differences based on dependence. To begin with, we note\n",
      "the general principle that status and dependence are almost never\n",
      "completely distinct [48], since a person in a high-status role fre-\n",
      "quently appears in situations where people are dependent on them.\n",
      "The data, however, offers us opportunities to study forms of de-\n",
      "pendence where the level of status has been largely controlled for.\n",
      "Key among these are forms of dependence created by the need to\n",
      "convince someone who disagrees with you. If you are advocating a\n",
      "position in a debate with opposing sides leading to an eventual de-\n",
      "\n",
      "6http://www.supremecourt.gov/oral_arguments/\n",
      "7http://scdb.wustl.edu/\n",
      "8In 2011, Justice Thomas marked ﬁve terms without speaking in\n",
      "any oral arguments. [34]\n",
      "9Throughout the paper we use color coding to indicate the relative\n",
      "power relations relevant for the respective discussion. These col-\n",
      "ors are simply intended as a helpful mnemonic and can be ignored\n",
      "without any loss of meaning.\n",
      "\n",
      "cision (for example, a Supreme Court case, or a policy discussion\n",
      "on Wikipedia prior to a vote), then your audience can be roughly\n",
      "divided into two groups: people who would naturally tend to vote\n",
      "in favor of your position, and people who would naturally tend to\n",
      "vote against your position. Principles of exchange theory indicate\n",
      "that in such situations, you are more dependent on the people who\n",
      "would naturally vote against you, and less dependent on the people\n",
      "who would naturally vote for you, since in order to accomplish your\n",
      "goal, you need to effect a more substantial behavior change in the\n",
      "former group [14, 30, 52]. An important further point here is that\n",
      "in our settings, participants can readily anticipate, either through\n",
      "dialogue or advance knowledge, who is “on their side” and who is\n",
      "“on the other side,” and so it makes sense to suppose that they are\n",
      "aware of these dependence relations during the interaction.\n",
      "\n",
      "Motivated by this, in the Supreme Court data we will compare\n",
      "levels of coordination of lawyers toward unfavorable Justices who\n",
      "(eventually) vote against their side and toward favorable Justices\n",
      "who (eventually) vote for their side; there is more dependence and\n",
      "hence more of a power difference in the former case. In the Wikipedia\n",
      "data, we will compare levels of coordination of editors with others\n",
      "who vote the opposite way and with others who vote the same way;\n",
      "here too, there is more dependence and hence more of a power\n",
      "difference in the former case. We should also note the exchange-\n",
      "theoretic principle that a dependence relation affects both sides:\n",
      "A’s dependence on B is expected not just to affect A’s behavior in\n",
      "their interaction, but B’s as well.\n",
      "\n",
      "4. LINGUISTIC STYLE COORDINATION\n",
      "As discussed earlier, we use linguistic style coordination to quan-\n",
      "tify the degree to which one individual immediately echoes the lin-\n",
      "guistic style of the person they are responding to. Here, linguistic\n",
      "style is quantiﬁed by a person’s usage of certain linguistic style\n",
      "markers (= categories of function words). We ﬁrst describe these\n",
      "markers, then give formal deﬁnitions of coordination.\n",
      "4.1 Linguistic style markers\n",
      "\n",
      "We measure the linguistic style of a person by their usage of cate-\n",
      "gories of function words that have little semantic meaning, thereby\n",
      "marking style rather than content.\n",
      "\n",
      "For consistency with prior work, we employed eight of the nine\n",
      "LIWC-derived categories [41] deemed to be processed by humans\n",
      "in a generally non-conscious fashion [28]. Our eight markers are\n",
      "thus: articles, auxiliary verbs, conjunctions, high-frequency ad-\n",
      "verbs, impersonal pronouns, personal pronouns, prepositions, and\n",
      "quantiﬁers (451 lexemes total).10\n",
      "4.2 Coordination measures\n",
      "\n",
      "Here we present a variation and further analysis of the measure\n",
      "\n",
      "introduced in [10], adapted to the setting of group conversations.\n",
      "Coordination with respect to a marker. We start by deﬁning\n",
      "the coordination of one person b towards another person a with\n",
      "respect to a speciﬁc linguistic style marker m. We want to quantify\n",
      "how much the use of marker class m in an utterance of a’s triggers\n",
      "the occurrence of m in b’s immediate (meaning next) reply to that\n",
      "utterance. To put it another way, we want to measure how much a’s\n",
      "use of m in an utterance u1 increases the probability that b will use\n",
      "m in his reply u2, where the increase is relative to b’s normal usage\n",
      "of m in conversations with a. We stress that we are thus looking at\n",
      "a more subtle phenomenon than whether b uses articles (say) more\n",
      "\n",
      "10We discarded negation because it is sparse and seems to carry\n",
      "semantic meaning. [28] also discarded some negations.\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France702\f",
      "overall when talking to a: we want to see whether b is so inﬂuenced\n",
      "by a as to change their function-word usage in their very next reply.\n",
      "Recall from §2 that we call b the speaker and a the target of a\n",
      "conversational exchange (a : u1, b : u2), since a is the target of b’s\n",
      "reply when b speaks. We say an utterance exhibits m if it contains\n",
      "a word from category m. Let E m\n",
      "u1 be the event that utterance u1\n",
      "(spoken to b) exhibits m; similarly, let E m\n",
      "u2(cid:44)→u1 be the event that\n",
      "reply u2 to u1 exhibits m.\n",
      "\n",
      "Given a set Sa,b of exchanges (a : u1, b : u2), we deﬁne the\n",
      "\n",
      "coordination of b towards a as:\n",
      "Cm(b, a) = P (E m\n",
      "\n",
      "u2(cid:44)→u1 | E m\n",
      "\n",
      "u1 ) − P (E m\n",
      "\n",
      "u2(cid:44)→u1 ),\n",
      "\n",
      "(1)\n",
      "\n",
      "where the probabilities are estimated over Sa,b, and where we re-\n",
      "quire that at least one of a’s utterances exhibits m in order for the\n",
      "ﬁrst quantity to be deﬁned.\n",
      "Properties. Eqn. (1) has several interesting properties. One non-\n",
      "obvious but important and useful characteristic is that it is a func-\n",
      "tion not only of b’s behavior, but also of a’s, because it can be\n",
      "shown that (1) lies in the interval [− (1 − P (E m\n",
      "u1 )].\n",
      "To see why a’s behavior needs to be taken into account, consider\n",
      "one extreme case: where every utterance of a to b exhibits m. Then\n",
      "Cm(b, a) = 0 no matter what b does in response, which makes\n",
      "sense because we have no evidence that any (or no) usage of articles\n",
      "by b is done in response to what a does — we don’t have any test\n",
      "cases to see what b does when a doesn’t employ a marker.\n",
      "\n",
      "u1 )) , 1 − P (E m\n",
      "\n",
      "Another extreme case is also illustrative: where a uses m only a\n",
      "few times when speaking to b, and b uses m when and only when\n",
      "a does. Then, Cm(b, a) approaches 1 as P (E m\n",
      "u1 ) approaches zero.\n",
      "Again, this makes intuitive sense: it is very unlikely that b matching\n",
      "a exactly on the few times a used m is due merely to chance.\n",
      "\n",
      "Another property of measure (1) is that it is not symmetric, which\n",
      "ﬁts the purpose of this study well, since the power relations we want\n",
      "to investigate are also asymmetric. See [11] for further discussion\n",
      "on the asymmetry.\n",
      "Coordination towards a group.\n",
      "In the context of group conver-\n",
      "sations, we can extend this deﬁnition to coordination of a particular\n",
      "speaker b towards a group of targets A by simply modifying the\n",
      "set of exchanges on which the probabilities in (1) are estimated.\n",
      "Speciﬁcally, given a set SA,b of exchanges (a : u1, b : u2) involv-\n",
      "ing initial utterances u1 of various targets a ∈ A and replies u2 of\n",
      "b, the coordination of b to the group A is:\n",
      "u2(cid:44)→u1 | E m\n",
      "\n",
      "Cm(b, A) = P (E m\n",
      "\n",
      "u1 ) − P (E m\n",
      "\n",
      "u2(cid:44)→u1 ),\n",
      "\n",
      "(2)\n",
      "\n",
      "but where this time the probabilities are estimated over SA,b.\n",
      "\n",
      "We then deﬁne the coordination of one group of people B to-\n",
      "wards another group A as the average coordination of speakers in\n",
      "B to targets in A:\n",
      "\n",
      "Cm(B, A) = (cid:104)Cm(b, A)(cid:105)b∈B\n",
      "\n",
      "(3)\n",
      "\n",
      "By taking the macro (unweighted) average, our measure will not be\n",
      "dominated by a few active speakers in a dataset.\n",
      "Aggregated measures.\n",
      "It is important to note that in general,\n",
      "coordination is multimodal: it does not necessarily occur simulta-\n",
      "neously for all markers [17], and speakers may coordinate on some\n",
      "features but diverge on others [47]. Hence, we also use aggregated\n",
      "measures of coordination of B to A to provide an overall picture of\n",
      "the level of coordination between the groups.\n",
      "\n",
      "Ideally we want to simply compute C(b, A) as the macro-average\n",
      "of Cm(b, A) across different markers m, and then compute C(B, A)\n",
      "the same way as in (3). Recall, however, that Cm(b, A) can only\n",
      "be computed if SA,b contains enough exchanges exhibiting m to\n",
      "reliably estimate both probabilities in (2), which is not always the\n",
      "\n",
      "case for all people with respect to all markers. For instance, some\n",
      "persons rarely use quantiﬁers, leaving C quant undeﬁned in those\n",
      "instances.\n",
      "\n",
      "We accounted for such “missing values” in three different ways,\n",
      "\n",
      "resulting in three aggregated measures:\n",
      "\n",
      "Aggregated 1 Compute the “ideal” macro-average C(b, A) only\n",
      "for the persons b for whom Cm(b, A) can be computed for\n",
      "all markers; ignore all the others. This reduces the set of\n",
      "persons considered by the aggregated measure, but provides\n",
      "the most direct measure (in the sense that it does not rely\n",
      "on any particular “smoothing” assumptions as the next two\n",
      "aggregated measures do).\n",
      "\n",
      "Aggregated 2 For each person b, if Cm(b, A) is undeﬁned, we\n",
      "“smooth” it by using the group average Cm(B, A) instead;\n",
      "this measure considers everybody for which we can compute\n",
      "coordination for at least one marker, but assumes that people\n",
      "in a given group share similar coordination behavior.\n",
      "\n",
      "Aggregated 3 For each person b, we take the average only over the\n",
      "markers for which Cm(b, A) is deﬁned; this is equivalent to\n",
      "assuming that b would have exhibited the same level of coor-\n",
      "dination for the missing markers as they did with other mark-\n",
      "ers. This aggregation also considers everybody for which we\n",
      "can compute coordination for at least one marker.\n",
      "\n",
      "4.3 Formalization of the power hypotheses\n",
      "\n",
      "Now that we have introduced a more formal deﬁnition of coordi-\n",
      "nation between two groups of people, we formalize the hypotheses\n",
      "introduced in §2 in terms of this deﬁnition. If people in a group\n",
      "Ghigh have more power than people in a group Glow, and U is a\n",
      "set of arbitrary people, the power hypotheses can be rewritten as:\n",
      "Ptarget: C(U, Ghigh) > C(U, Glow)\n",
      "Pspeaker: C(Ghigh, U ) < C(Glow, U )\n",
      "\n",
      "5. EMPIRICAL INVESTIGATION\n",
      "\n",
      "Using the concepts and formalism introduced in the previous\n",
      "sections, we can now investigate the relation between linguistic co-\n",
      "ordination and power differentials in concrete conversational set-\n",
      "tings. Speciﬁcally, we test whether the principle P and the hy-\n",
      "potheses Ptarget and Pspeaker introduced in §2 can be empirically\n",
      "conﬁrmed in the two datasets described in §3. We begin by dis-\n",
      "cussing power differences arising from status in Wikipedia (where\n",
      "our primary status distinction will be admins vs. non-admins) and\n",
      "in the Supreme Court (where our primary status distinction will be\n",
      "Justices vs.\n",
      "lawyers). After this, we consider power differences\n",
      "arising from dependence.\n",
      "5.1 Power from status: Wikipedia\n",
      "First, communication behavior on Wikipedia provides evidence\n",
      "for hypothesis Ptarget: users coordinate more toward the (higher-\n",
      "powered) admins than toward the non-admins (Figure 1(a)).11\n",
      "\n",
      "In the other direction, however, when comparing admins and\n",
      "non-admins as speakers, the data provides evidence that is initially\n",
      "\n",
      "11The major explanatory factor for these results does not appear to\n",
      "be wholesale repetition of phrases, even short ones. We note, for\n",
      "example, that with respect to the data used for computing conjunc-\n",
      "tion coordination, only 0.7% of the exchanges contain trigram re-\n",
      "peats involving conjunctions and only 3.5% contain bigram repeats\n",
      "involving conjunctions; and the difference in coordination levels re-\n",
      "mains signiﬁcant when exchanges with such repeats are discarded.\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France703\f",
      "(a) Supporting Ptarget\n",
      "\n",
      "(b) Contradicting Pspeaker\n",
      "\n",
      "(a) Before RfA elections (B)\n",
      "\n",
      "(b) In RfA discussions (B)\n",
      "\n",
      "Figure 1: Status and linguistic coordination: (a) Users coordi-\n",
      "nate more towards admins (high-powered) than towards non-\n",
      "admins (low-powered), supporting hypothesis Ptarget (indeed,\n",
      "signiﬁcantly so in aggregate: see later part of this caption).\n",
      "(b) On the other hand, admins (high-powered) coordinate more\n",
      "than non-admins (low-powered) when replying to other people,\n",
      "contradicting hypothesis Pspeaker.\n",
      "Note on all ﬁgures: ∗’s on the x-axis (e.g., “Article 1*”\n",
      "in (a)) indicate statistical signiﬁcance,\n",
      "independent t-test:\n",
      "*=“p<0.05”,**=“p<0.01”,***=“p<0.001”. Next to each legend\n",
      "label, in parentheses, are: the number of users for Aggregated\n",
      "1 (i.e., the users for which we can compute coordination for all\n",
      "markers) and the total number of users for Aggregated 2 and\n",
      "3 (i.e., the users for which we can compute coordination for at\n",
      "least one marker). “Error bars” do not indicate standard er-\n",
      "ror (we already marked statistical signiﬁcance with stars) but\n",
      "rather give an idea of how coordination values vary via the\n",
      "standard deviation, estimated by bootstrap resampling [29].\n",
      "The y-axis values are reported as percentages (i.e., multiplied\n",
      "by 100) for clarity.\n",
      "\n",
      "at odds with Pspeaker: as illustrated in Figure 1(b), admins coordi-\n",
      "nate to other people more than non-admins do (while the hypothesis\n",
      "predicted that they would coordinate less).12 We now explore some\n",
      "of the subtleties underlying this result, showing how it arises as a\n",
      "superposition of two effects.\n",
      "Personal characteristics: Hypothesis B. One possible explana-\n",
      "tion for the inconsistency of our observations with Pspeaker is the\n",
      "effect of personal characteristics suggested in Hypothesis B from\n",
      "§2. Speciﬁcally, admin status was not conferred arbitrarily on a set\n",
      "of users; rather, admins are those people who sought out this higher\n",
      "status and succeeded in achieving it. It is thus natural to suppose\n",
      "that, as a group, they may have distinguishing individual traits that\n",
      "are reﬂected in their level of language coordination.\n",
      "\n",
      "Fortunately we can extract rich enough data from Wikipedia that\n",
      "it becomes possible, to a signiﬁcant extent, to separate the effect\n",
      "of status from these individual traits, establishing that both effects\n",
      "play a role. Our separation of these effects is based on the fact that\n",
      "status can change abruptly, while personal characteristics, though\n",
      "mutable, are more stable over time. On Wikipedia, status changes\n",
      "\n",
      "12Note that the observations shown in Figure 1(a) do not imply those\n",
      "in Figure 1(b), nor vice-versa. For example, the trend in Figure 1(a)\n",
      "does not change if we restrict the speakers to be only non-admins\n",
      "(or only admins).\n",
      "\n",
      "Figure 2: Same-status comparisons (supporting a “winner”\n",
      "personality hypothesis):\n",
      "(a) admins-to-be coordinate more\n",
      "than those who remain non-admins thoughout; (b) during ad-\n",
      "minship elections (RfAs), admins-to-be coordinate more than\n",
      "failed-to-be.\n",
      "\n",
      "are well documented, as they can occur only through an election\n",
      "process instigated by requests for adminship (RfAs). When we\n",
      "compare the set of admins-to-be— future admins before they were\n",
      "promoted via their RfA — with non-admins, Figure 2(a) shows that\n",
      "the same differences in language coordination were already present\n",
      "in these two populations — hence, they are not an effect of status\n",
      "alone, since they were visible before the former population experi-\n",
      "enced a status upgrade.\n",
      "\n",
      "Can we separate the effects of ambition from success? Yes, be-\n",
      "cause we can look at differences in coordination between users\n",
      "who were promoted (admins-to-be), and those who went through\n",
      "the RfA process but were denied admin status (failed-to-be). Both\n",
      "admins-to-be and failed-to-be had the ambition to become admins,\n",
      "but only members of the former group succeeded. We investigate\n",
      "coordination differnces between these two groups during a period\n",
      "when their adminship ambitions are arguably most salient: during\n",
      "the discussions in each user’s own RfA process. Figure 2(b) shows\n",
      "that even in the conversations they had on their RfA pages, the\n",
      "admins-to-be were coordinating more to the others than the failed-\n",
      "to-be, providing evidence for a strong form of Hypothesis B.\n",
      "Revisiting status: Hypothesis P(cid:48)\n",
      "speaker. We now return to the\n",
      "issue of status, and describe a method of partially controlling for\n",
      "personal characteristics so as to evaluate the following modiﬁcation\n",
      "of Hypothesis Pspeaker:\n",
      "P(cid:48)\n",
      "speaker. When controlling for personal characteristics, high-\n",
      "\n",
      "powered people coordinate less than low-powered people.\n",
      "\n",
      "To study P(cid:48)\n",
      "\n",
      "speaker, we create two populations for comparison:\n",
      "the interactions of each admin before his or her promotion via RfA\n",
      "(i.e., when they were admins-to-be), and the interactions of each\n",
      "admin after his or her respective promotion. Figure 3(a) shows\n",
      "how the resulting comparison conﬁrms P(cid:48)\n",
      "speaker: admins-to-be de-\n",
      "crease their level of coordination once they gain power.13 Interest-\n",
      "ingly, the reverse seems to be true for failed-to-be: after failing\n",
      "13Note that the trend shown in Figure 3(a) is maintained when con-\n",
      "sidering the exact same users in both groups (i.e., excluding the\n",
      "\n",
      "Aggregated 1*Aggregated 2**Aggregated 3***QuantifierConjunction*Indef. pron.*Adverb*Article*Aux. verbPers. pron.Preposition0.00.51.01.52.02.53.03.54.0Coordinationtargets: admins (805, 1027)targets: non-admins (2307, 3637)Aggregated 1*Aggregated 2**Aggregated 3**Quantifier*Conjunction*Indef. pron.*AdverbArticle*Aux. verbPers. pron.Preposition0.00.51.01.52.02.53.03.54.0Coordinationspeakers: admins (805, 1027)speakers: non-admins (2029, 2856)Aggregated 1**Aggregated 2***Aggregated 3**Quantifier**Adverb*ConjunctionIndef. pron.Article*Aux. verb**Pers. pron.Preposition0.00.51.01.52.02.53.03.54.0Coordinationspeakers: admins-to-be (180, 277)speakers: non-admins (2029, 2856)Aggregated 1Aggregated 2**Aggregated 3*QuantifierArticle*ConjunctionIndef. pron.AdverbAux. verb*PrepositionPers. pron.0.00.51.01.52.02.53.03.54.0Coordinationspeakers: admins-to-be (44, 81)speakers: falied-to-be (131, 227)WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France704\f",
      "(a) Supporting P(cid:48)\n",
      "\n",
      "speaker\n",
      "\n",
      "(b) Timed\n",
      "change (P)\n",
      "\n",
      "effect\n",
      "\n",
      "of\n",
      "\n",
      "status\n",
      "\n",
      "Figure 3: Effect of status change. (a) admins-to-be coordinate\n",
      "less after they become admins; (b) Aggregated 1 coordination\n",
      "of the user (as speaker) and, respectively, towards the user (as\n",
      "target) before and after status change occurs through RfA.\n",
      "\n",
      "in their RfAs — an event that arguably reinforces their failure to\n",
      "achieve high status in the community — they coordinate more (\n",
      "p-value < 0.05; ﬁgure omitted due to space limitations).\n",
      "In addition, we can employ status change to reinforce Ptarget\n",
      "in a setting that controls for personal characteristics: we ﬁnd that\n",
      "users coordinate more to admins after promotion than when they\n",
      "were admins-to-be (p-value<0.05).\n",
      "\n",
      "Finally, in Figure 3(b), we investigate how quickly the change\n",
      "in status is reﬂected in the communication behavior of the users\n",
      "involved.\n",
      "In addition to the monotonic changes in coordination\n",
      "levels over time, and in the hypothesized directions, it is interesting\n",
      "to note that the most dramatic change in coordination is visible in\n",
      "the second month after the change in status occurred. This suggests\n",
      "a period of acclimation to the newly gained status, both for the\n",
      "person that undergoes the change and for those witnessing it.\n",
      "5.2 Power from status: Supreme Court\n",
      "\n",
      "In the setting of the Supreme Court, status differences are ex-\n",
      "tremely salient and do not suffer from the correlations that added\n",
      "complexity to the study of Pspeaker in its original form. Also, con-\n",
      "versations during the oral arguments (almost) always are between a\n",
      "Justice and a lawyer. Thus, our basic ﬁnding can be expressed suc-\n",
      "cinctly in Figure 4, which shows signiﬁcantly more coordination\n",
      "from lawyers to Justices than vice versa.14.\n",
      "\n",
      "In the Supreme Court setting we can also study ﬁner-grained sta-\n",
      "tus distinctions, to see if these too are manifested in language coor-\n",
      "dination differences. Indeed, in concordance with Ptarget, we ob-\n",
      "serve that lawyers coordinate signiﬁcantly more toward the Chief\n",
      "Justice than toward the Associate Justices (p-value<0.01).\n",
      "\n",
      "users which did not have enough conversations both before and af-\n",
      "ter adminship). Also note that we allow a time buffer of a month\n",
      "after the RfAs between the two sets of conversations we compare.\n",
      "14Throughout, we consider each appearance of a given Justice or\n",
      "lawyer in a different case as a separate entity, which allows for\n",
      "different behaviors in different cases and increases the number of\n",
      "datapoints.\n",
      "\n",
      "Figure 4: Lawyers coordinate more to Justices than conversely.\n",
      "\n",
      ".\n",
      "\n",
      "(a) Dependence: Ptarget\n",
      "\n",
      "(b) Dependence: Pspeaker\n",
      "\n",
      "Figure 5: Dependence and linguistic coordination: (a) lawyers\n",
      "adjust their coordination level according to whether the Justice\n",
      "is unfavorable or favorable, supporting Ptarget; (b) favorable\n",
      "Justices coordinate more than unfavorable Justices (Pspeaker).\n",
      "\n",
      "5.3 Power from dependence\n",
      "\n",
      "As noted in §3, we can study power differences based on de-\n",
      "pendence — even for ﬁxed levels of status difference — using\n",
      "the exchange-theoretic principle that the need to convince someone\n",
      "who disagrees with you creates a form of dependence [14, 30, 52].\n",
      "Moreover, this power difference is predicted to be felt by both sides\n",
      "— the side with lower power and the side with higher power.\n",
      "\n",
      "In the case of lawyer-Justice interactions, let us deﬁne the Jus-\n",
      "tice to be favorable to the lawyer if he or she ends up voting on the\n",
      "lawyer’s side, and unfavorable if he or she ends up voting against\n",
      "the lawyer’s side. It is well understood that the Justices often come\n",
      "into the case with a general leaning toward one side or the other\n",
      "based on their judicial philosophy — this has been acknowledged\n",
      "for example in interviews with members of the Court [43] — and\n",
      "lawyers through their preparation for the case will come in with\n",
      "knowledge of these leanings. Hence it is reasonable to suppose that\n",
      "the favorable-unfavorable distinction will be salient to the interac-\n",
      "tion during oral arguments.\n",
      "\n",
      "And indeed, Figures 5(a) and 5(b) show that the power differ-\n",
      "ences created by this form of dependence are reﬂected in the amount\n",
      "of coordination, in both directions. First, lawyers coordinate more\n",
      "\n",
      "Aggregated 1*Aggregated 2*Aggregated 3QuantifierConjunctionAdverbIndef. pron.ArticleAux. verb**Pers. pron.Preposition0.00.51.01.52.02.53.03.54.0Coordinationspeaker before RfA (184, 281)speaker after RfA (762, 974)prev. monthStatus change1st month2nd month3rd month0.00.51.01.52.02.53.03.54.0Coordinationadmin-to-beadminas speakeras targetAggregated 1***Aggregated 2***Aggregated 3***Quantifier**Adverb*ConjunctionArticle*Pers. pron.***Indef. pron.***Preposition***Aux. verb***0123456CoordinationJustices to lawyers (815, 1307)lawyers to Justices (500, 535)Aggregated 1*Aggregated 2***Aggregated 3***Quantifier*Adverb*Pers. pron.**Indef. pron.*Article*Preposition**ConjunctionAux. verb0123456Coordinationtarget: unfavorable Justice (302, 913)target: favorable Justice (135, 644)Aggregated 1*Aggregated 2**Aggregated 3QuantifierAdverb**ConjunctionArticlePers. pron.Indef. pron.PrepositionAux. verb0123456Coordinationspeaker: unfavorable Justice (346, 888)speaker: favorable Justice (197, 641)WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France705\f",
      "toward unfavorable Justices (on whom they are more dependent)\n",
      "than toward favorable Justices, in keeping with Ptarget. Second,\n",
      "unfavorable Justices coordinate less toward lawyers than favorable\n",
      "Justices do, in keeping with Pspeaker. Given the formal frame-\n",
      "work of impartiality that characterizes the Justices’s behavior at the\n",
      "Supreme Court, it is intriguing to see the undercurrent of language\n",
      "coordination differences nevertheless hinting at their eventual deci-\n",
      "sion.\n",
      "\n",
      "We see a similar effect of dependence on coordination in the\n",
      "context of discussions with opposing sides on Wikipedia. During\n",
      "RfAs, one voter may try to change the opinion of voters on the\n",
      "other side who have already cast their vote. (Changing your vote\n",
      "during the RfA process is allowed, and hence there is an incentive\n",
      "to convince voters to consider this.) Users coordinated more when\n",
      "engaging with users on the opposite side than with those who voted\n",
      "the same way (p-value<0.05; for space reasons we omit the ﬁgure).\n",
      "This ﬁnding too, via the arguments about opposing sides and de-\n",
      "pendence, supports the general power-coordination principle P.\n",
      "\n",
      "6. CROSS-DOMAIN ANALYSIS AND INTER-\n",
      "\n",
      "ACTION AMONG HYPOTHESES\n",
      "\n",
      "6.1 Coordination as a Cross-Domain Feature\n",
      "Part of the motivation for studying the relation between coor-\n",
      "dination and power is that the principles that govern this relation\n",
      "appear to be domain-independent. Here we perform a set of anal-\n",
      "yses to show that coordination features do generalize across our\n",
      "two domains more effectively than other text-based features for the\n",
      "problem of inferring power. We ﬁnd that indeed, compared to the\n",
      "other features we consider, they are the only set of features to dis-\n",
      "play any non-trivial generalization.\n",
      "\n",
      "Our analysis is based on the following prediction task: for a\n",
      "given pair of different-status people x and y who have engaged in\n",
      "conversations with each other, we predict whether x has the higher\n",
      "status. In this setting, a random guess baseline would achieve 50%\n",
      "accuracy. We stress, however, that this prediction task is primarily\n",
      "a means to assess cross-domain generalization, i.e., not as a free-\n",
      "standing task in itself. Indeed, the best achievable performance on\n",
      "this status-prediction task appears to be quite domain-dependent. In\n",
      "some domains such as the Supreme Court, idiosyncratic cues in text\n",
      "usage (e.g., lawyers begin their sentences with stylized lead-ins,\n",
      "such as “Your honor”, that clearly mark them as lawyers, not Jus-\n",
      "tices) enable almost perfect performance when these cues are avail-\n",
      "able as features. In other domains, such as Wikipedia, an informal\n",
      "evaluation using two human annotators familiar with the domain\n",
      "produced only 70% accuracy (and an inter-annotator agreement of\n",
      "only 80%). Thus, our interest is not in whether coordination fea-\n",
      "tures achieve the best within-domain performance, but in whether\n",
      "they are particularly effective at generalizing (as we indeed ﬁnd\n",
      "them to be).\n",
      "Experimental setup. Let Rx be x’s replies to y, and Ry be y’s\n",
      "replies to x, and Len(S) be the average length of all utterances in\n",
      "the set S. Let Fstyle be the set of 8 stylistic markers introduced in\n",
      "§4.1. We deﬁne the following sets of features used as input to an\n",
      "SVM classiﬁer:\n",
      "\n",
      "• coordination features: binary features indicating, for each\n",
      "m ∈ Fstyle as well as for Aggregated 115, whether x co-\n",
      "ordinates more to y than y to x on m\n",
      "\n",
      "15We only considered pairs of participants for which enough data\n",
      "was available to compute coordination on all stylistic features.\n",
      "\n",
      "coordination features (9 altogether)\n",
      "stylistic features (18 altogether)\n",
      "bag of words (20,000 altogether)\n",
      "\n",
      "Training corpus wiki\n",
      "Test corpus wiki\n",
      "57.7\n",
      "59.2\n",
      "51.4\n",
      "\n",
      "in-domain\n",
      "court\n",
      "court\n",
      "70.4\n",
      "51.4\n",
      "99.5\n",
      "\n",
      "cross-domain\n",
      "wiki\n",
      "court\n",
      "wiki\n",
      "court\n",
      "55.0\n",
      "57.1\n",
      "51.9\n",
      "50.0\n",
      "45.2\n",
      "40.1\n",
      "\n",
      "Table 2: Prediction accuracy for SVM’s using various feature\n",
      "sets. Cross-domain results are in the right-hand two columns.\n",
      "Bold = results signiﬁcantly better than chance.\n",
      "\n",
      "• stylistic features: frequency of each marker m ∈ Fstyle in\n",
      "Rx and, respectively, in Ry; also, Len(Rx), Len(Ry). We\n",
      "use this feature set to examine whether style alone is predic-\n",
      "tive on its own, or whether speciﬁcally stylistic coordination\n",
      "is key\n",
      "\n",
      "• bag of words: frequency of each word in Rx, frequency of\n",
      "\n",
      "each word in Ry, L2-normalized\n",
      "\n",
      "For experiments on the Wikipedia data, which we denote as wiki,\n",
      "we considered (admin, non-admin) pairs (for conversations occur-\n",
      "ring after the admins were elected). For the Supreme Court dataset\n",
      "(court), we considered (Justice, lawyer) pairs16.\n",
      "\n",
      "For in-domain experiments, we report average accuracy over cross-\n",
      "\n",
      "validation within the same domain (i.e., training and test corpora\n",
      "are both wiki or court); for cross-domain experiments, we train on\n",
      "one domain and test on the other.\n",
      "Results. Table 2 summarizes the results. We ﬁnd that coordination\n",
      "features are the only ones to perform statistically signiﬁcantly bet-\n",
      "ter than random guessing in the cross-domain settings — the other\n",
      "classiﬁers simply learn cues that are idiosyncratic to their training\n",
      "data, and fail to generalize.\n",
      "(Note for example that the bag-of-\n",
      "words method picks up on the near-perfect lexical cues marking\n",
      "lawyers in the Supreme Court data, but this method performs worse\n",
      "than random guessing when applied to the other domain.)\n",
      "\n",
      "Even looking at the in-domain tasks — which were not our\n",
      "primary focus here — we ﬁnd that coordination features are the\n",
      "only ones that perform statistically signiﬁcantly better than random\n",
      "guessing on both datasets.\n",
      "6.2 Interactions among Hypotheses P and B\n",
      "In §5 we saw that the interaction between personal characteris-\n",
      "tics (which form the basis for Hypothesis B) and power differen-\n",
      "tials (which form the basis for Hypothesis P) can lead to complex\n",
      "effects. Here we consider two cases where this interaction raises\n",
      "interesting issues, and point to open questions in the analysis of\n",
      "coordination.\n",
      "\n",
      "An individual’s level of social engagement is one type of per-\n",
      "sonal characteristic that interacts with coordination and power. As\n",
      "a simple proxy for social engagement, for purposes of discussion\n",
      "here, we consider the volume of communication the individual en-\n",
      "gages in. As we noted in §1, simple volume measures such as this\n",
      "do not seem to readily yield domain-independent information about\n",
      "power, since they vary considerably across domains — in some do-\n",
      "mains the powerful people talk a lot, and in others they talk rel-\n",
      "atively little. For example, when people are promoted to admin\n",
      "status, their volume of communication goes up while (as we have\n",
      "\n",
      "16In order to focus on the conversational exchanges and avoid ex-\n",
      "changes in which the lawyers formally introduce their case, we\n",
      "considered only cases where the length difference between the two\n",
      "utterances were fewer than 20 words.\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France706\f",
      "seen) their level of coordination goes down. On the other hand,\n",
      "lawyers talk more than Justices in the Supreme Court data, and\n",
      "(again as we have seen) they also coordinate more in the lawyer-\n",
      "Justice interactions.\n",
      "\n",
      "However, if we restrict attention to a ﬁxed sub-population within\n",
      "a given domain, there are interesting connections between coor-\n",
      "dination and volume that suggest further questions. In particular,\n",
      "on Wikipedia we consider the number of replies posted by a user\n",
      "on talk-pages as a measure of communication volume, and hence a\n",
      "proxy for their level of social engagement on the site. We compared\n",
      "users in the top 1/3 of the sorted order by communication volume\n",
      "with users in the bottom 1/3, ﬁnding that users with higher numbers\n",
      "of replies are more likely to coordinate to others (p-value<0.05).\n",
      "We observed the same effect when we compared the communica-\n",
      "tion volumes of users with the same status: among admins, users\n",
      "with more communication are also more likely to coordinate, and\n",
      "the same trend holds among non-admins. Similar effects also hold\n",
      "for other measures of communication volume. Again, we note that\n",
      "other domains (such as the Supreme Court) show an inverse rela-\n",
      "tion between volume and coordination in the communication tran-\n",
      "scripts, and so it is an interesting question to identify the principles\n",
      "that determine how this relationship plays out in different settings.\n",
      "We also consider a second basic example that raises an interest-\n",
      "ing challenge for distinguishing between Hypotheses P and B: the\n",
      "effect of gender on coordination, using the fact that gender infor-\n",
      "mation is available for participants in the Supreme Court dataset.\n",
      "\n",
      "(a) gender differences in speakers\n",
      "\n",
      "(b) gender differences in targets\n",
      "\n",
      "Figure 6: Gender differences\n",
      "\n",
      "The main ﬁnding here, in Figure 6, is that overall female lawyers\n",
      "coordinate more than male lawyers when talking to Justices, and\n",
      "correspondingly, Justices coordinate more towards male lawyers\n",
      "than towards female lawyers. Given the extensive history of work\n",
      "exploring culturally-embedded status and power differences based\n",
      "on gender [3, 48], one interpretation of this ﬁnding is directly in\n",
      "terms of Hypothesis P. However, since it is also potentially re-\n",
      "lated to theories of gender-based communication differences [26]\n",
      "and even gender-based language adaptation differences [40], the\n",
      "question of separating Hypotheses P and B becomes challenging\n",
      "here. We think it is a promising possibility that language coordina-\n",
      "tion effects may be able to serve as a lens through which to measure\n",
      "many similar kinds of distinctions in both on-line and off-line con-\n",
      "versational settings.\n",
      "\n",
      "7. FURTHER RELATED WORK\n",
      "\n",
      "In the opening sections, we have discussed some of the ways in\n",
      "which earlier work used text content to analyze on-line networks\n",
      "[9, 12, 19, 35, 54], as well as background on language coordina-\n",
      "tion and the exchange-theoretic notions of power from status and\n",
      "dependence. Here we discuss some further work that is related to\n",
      "the general issues we consider here.\n",
      "Power and structural features. There has been extensive work\n",
      "on using structural features, rather than language, to infer notions of\n",
      "“importance” in networks, both in the literature on social networks\n",
      "[16] and on the Web [8]. Recent work has also studied the inference\n",
      "of status from on-line social network features [23, 33].\n",
      "Power and language.\n",
      "The relation between linguistic coordi-\n",
      "nation17 and status has mostly been examined in small-scale con-\n",
      "texts: 15 Watergate transcripts [39], 40 courtroom cases [1], or a\n",
      "single simulated courtroom trial [15]. A recent large-scale study of\n",
      "language coordination in the on-line domain [10] used data from\n",
      "Twitter, where markers of status and power are not as readily in-\n",
      "ferred; they identiﬁed a weak correlation between language coordi-\n",
      "nation and Twitter follower counts, suggesting a potential connec-\n",
      "tion to status measures. Additionally, researchers have used text\n",
      "features other than linguistic coordination to identify status differ-\n",
      "ences [5, 13, 18, 37, 44]; in contrast with our work, these methods\n",
      "picked up situation-speciﬁc cues, such as the word “termination”\n",
      "for the Enron corporate-email corpus [13], which are unlikely to\n",
      "generalize across contexts.\n",
      "Collaborative communities.\n",
      "Interaction in online communities\n",
      "has been extensively studied. Wikipedia was used as a testbed for\n",
      "studying user interaction at large [4, 31, 36, 46, 50] and the promo-\n",
      "tion process in such communities [7, 32]. Reviewer behavior and\n",
      "incentives to participate in the collaborative process were studied\n",
      "in the context of commercial review sites [6, 19, 36, 53].\n",
      "\n",
      "Acknowledgments. We thank Timothy Hawes for sharing the processed\n",
      "Supreme Court transcripts from [25], and B. Abrahao, E. Baumer, C. Cardie,\n",
      "E. Choi, C. Diehl, S. Dumais, S. Edelman, J. Eisenstein, M. Gamon,\n",
      "S. Herring, M.\n",
      "Ireland, D. Minculescu, A. Niculescu-Mizil, M. Ott,\n",
      "J. Park, P. Resnik, D. Romero, C. Tan, L. Wang, B. Yang, A. Yesse-\n",
      "nalina, and the anonymous reviewers for valuable discussions and sugges-\n",
      "tions. This paper is based upon work supported in part by the NSF grant\n",
      "IIS-0910664, IIS-1016099, and grants from Google and Yahoo!.\n",
      "\n",
      "References\n",
      "[1] K. Aronsson, L. Jönsson, P. Linell. The courtroom hearing as a\n",
      "\n",
      "middle ground: Speech accommodation by lawyers and defendants.\n",
      "J. Lang. and Social Psych., 6(2):99–115, 1987.\n",
      "\n",
      "[2] A. Bell. Language style as audience design. Language in Society,\n",
      "\n",
      "13(2):145–204, 1984.\n",
      "\n",
      "[3] J. Berger, B. P. Cohen, M. Zelditch Jr. Status characteristics and\n",
      "\n",
      "social interaction. American Sociological Review, 37(3):241–255,\n",
      "1972.\n",
      "\n",
      "[4] M. Billings, L. A. Watts. Understanding dispute resolution online:\n",
      "\n",
      "Using text to reﬂect personal and substantive issues in conﬂict. CHI,\n",
      "1447–1456, 2010.\n",
      "\n",
      "[5] P. Bramsen, M. Escobar-Molana, A. Patel, R. Alonso. Extracting\n",
      "\n",
      "social power relationships from natural language. ACL HLT, 2011.\n",
      "\n",
      "[6] S. L. Bryant, A. Forte, A. Bruckman. Becoming Wikipedian:\n",
      "\n",
      "transformation of participation in a collaborative online\n",
      "encyclopedia. GROUP, 1–10, 2005.\n",
      "\n",
      "17For brevity, we exclude studies of the effects of status on other\n",
      "types of coordination, such as pitch and vocal features, which are\n",
      "absent from textually-manifested discussions (see [20] for a survey)\n",
      "or on related phenomena such as information-density matching [1].\n",
      "\n",
      "Aggregated 1*Aggregated 2**Aggregated 3*QuantifierAdverb*Pers. pron.Indef. pron.*ConjunctionArticle*Preposition**Aux. verb0123456Coordinationspeaker: male lawyers (405, 435)speaker: female lawyers (81, 85)Aggregated 1**Aggregated 2**Aggregated 3*QuantifierAdverbConjunction*Article*Pers. pron.Preposition*Indef. pron.Aux. verb0123456Coordinationtarget: male lawyers (426, 436)target: female lawyers (85, 85)WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France707\f",
      "[7] M. Burke, R. Kraut. Mopping up: Modeling Wikipedia promotion\n",
      "\n",
      "decisions. CSCW, 27–36, 2008.\n",
      "\n",
      "[30] J. P. Kotter. Power, dependence, and effective management. Harvard\n",
      "\n",
      "Business Review, 125–136, July 1977.\n",
      "\n",
      "[8] S. Chakrabarti. Mining the Web: discovering knowledge from\n",
      "\n",
      "hypertext data. Morgan Kaufmann, 2003.\n",
      "\n",
      "[9] M. D. Conover, J. Ratkiewicz, M. Francisco, B. Goncalves,\n",
      "\n",
      "A. Flammini, F. Menczer. Political polarization on Twitter. ICWSM,\n",
      "2011.\n",
      "\n",
      "[10] C. Danescu-Niculescu-Mizil, M. Gamon, S. Dumais. Mark my\n",
      "words! Linguistic style accommodation in social media. WWW,\n",
      "2011.\n",
      "\n",
      "[11] C. Danescu-Niculescu-Mizil, L. Lee. Chameleons in imagined\n",
      "\n",
      "conversations: A new approach to understanding coordination of\n",
      "linguistic style in dialogs. ACL Cognitive Modeling and\n",
      "Computational Linguistics Workshop, 2011.\n",
      "\n",
      "[12] M. De Choudhury, W. A. Mason, J. M. Hofman, D. J. Watts.\n",
      "\n",
      "Inferring relevant social networks from interpersonal\n",
      "communication. WWW, 301–310, 2010.\n",
      "\n",
      "[13] C. P. Diehl, G. Namata, L. Getoor. Relationship identiﬁcation for\n",
      "social network discovery. Proceedings of the AAAI Workshop on\n",
      "Enhanced Messaging, volume 22, 546–552, 2007.\n",
      "\n",
      "[14] R. M. Emerson. Power-dependence relations. American Sociological\n",
      "\n",
      "Review, 27:31–40, 1962.\n",
      "\n",
      "[15] B. Erickson, E. A. Lind, B. C. Johnson, W. M. O’Barr. Speech style\n",
      "\n",
      "and impression formation in a court setting: The effects of\n",
      "\"powerful\" and \"powerless\" speech. J. Experimental Social\n",
      "Psychology, 14(3):266 – 279, 1978.\n",
      "\n",
      "[16] K. Faust, S. Wasserman. Social network analysis: Methods and\n",
      "\n",
      "applications. Cambridge University Press New York, 1994.\n",
      "\n",
      "[17] K. Ferrara. Accommodation in therapy. Accommodation theory:\n",
      "\n",
      "Communication, context, and consequences. Cambridge University\n",
      "Press, 1991.\n",
      "\n",
      "[18] E. Gilbert. Phrases that signal workplace hierarchy. CSCW, 2012.\n",
      "[19] E. Gilbert, K. Karahalios. Predicting tie strength with social media.\n",
      "\n",
      "CHI, 211–220, 2009.\n",
      "\n",
      "[20] H. Giles. Communication Accommodation Theory. Engaging\n",
      "\n",
      "theories in interpersonal communication: Multiple perspectives,\n",
      "161–173. Sage Publications, Inc, 2008.\n",
      "\n",
      "[21] H. Giles, J. Coupland, N. Coupland. Accommodation theory:\n",
      "\n",
      "Communication, context, and consequence. Contexts of\n",
      "accommodation: Developments in applied sociolinguistics.\n",
      "Cambridge University Press, 1991.\n",
      "\n",
      "[22] J. Gregory, Stanford W., S. Webster. A nonverbal signal in voices of\n",
      "\n",
      "interview partners effectively predicts communication\n",
      "accommodation and social status perceptions. J. Personality and\n",
      "Social Psych., 70(6):1231, 1996.\n",
      "\n",
      "[23] R. Guha, R. Kumar, P. Raghavan, A. Tomkins. Propagation of trust\n",
      "\n",
      "and distrust. WWW, 403–412, 2004.\n",
      "\n",
      "[24] T. Hawes. Computational analysis of the conversational dynamics of\n",
      "\n",
      "the United States Supreme Court. Master’s thesis, University of\n",
      "Maryland, 2009.\n",
      "\n",
      "[25] T. Hawes, J. Lin, P. Resnik. Elements of a computational model for\n",
      "multi-party discourse: The turn-taking behavior of Supreme Court\n",
      "justices. JASIST, 60(8):1607–1615, 2009.\n",
      "\n",
      "[26] S. C. Herring. Gender and power in on-line communication. The\n",
      "\n",
      "Handbook of Language and Gender, 202–228. 2003.\n",
      "\n",
      "[27] L. Huang, A. D. Galinsky, D. H. Gruenfeld, L. E. Guillory. Powerful\n",
      "\n",
      "Postures Versus Powerful Roles. Psychological Science,\n",
      "22(1):95–102, 2011.\n",
      "\n",
      "[28] M. E. Ireland, R. B. Slatcher, P. W. Eastwick, L. E. Scissors, E. J.\n",
      "\n",
      "Finkel, J. W. Pennebaker. Language style matching predicts\n",
      "relationship initiation and stability. Psychological Science, 22:39–44,\n",
      "2011.\n",
      "\n",
      "[29] P. Koehn. Statistical signiﬁcance tests for machine translation\n",
      "\n",
      "evaluation. EMNLP, 388–395, 2004.\n",
      "\n",
      "[31] D. Laniado, R. Tasso, Y. Volkovich, A. Kaltenbrunner. When the\n",
      "\n",
      "Wikipedians talk: Network and tree structure of Wikipedia\n",
      "discussion pages. ICWSM, 2011.\n",
      "\n",
      "[32] J. Leskovec, D. Huttenlocher, J. Kleinberg. Governance in Social\n",
      "\n",
      "Media: A case study of the Wikipedia promotion process. ICWSM,\n",
      "2010.\n",
      "\n",
      "[33] J. Leskovec, D. Huttenlocher, J. Kleinberg. Predicting positive and\n",
      "\n",
      "negative links in online social networks. WWW, 641–650, 2010.\n",
      "\n",
      "[34] A. Liptak. Clarence Thomas Keeps 5-Year Supreme Court Silence.\n",
      "\n",
      "The New York Times, February 2011.\n",
      "\n",
      "[35] A. Livne, M. P. Simmons, E. Adar, L. A. Adamic. The party is over\n",
      "\n",
      "here: Structure and content in the 2010 election. ICWSM, 2011.\n",
      "\n",
      "[36] Y. Lu, P. Tsaparas, A. Ntoulas, L. Polanyi. Exploiting social context\n",
      "\n",
      "for review quality prediction. WWW, 691–700, 2010.\n",
      "\n",
      "[37] A. McCallum, X. Wang, A. Corrada-Emmanuel. Topic and role\n",
      "\n",
      "discovery in social networks with experiments on Enron and\n",
      "academic email. JAIR, 30(1):249–272, 2007.\n",
      "\n",
      "[38] M. Natale. Convergence of mean vocal intensity in dyadic\n",
      "\n",
      "communication as a function of social desirability. J. Personality and\n",
      "Social Psych., 32(5):790 – 804, 1975.\n",
      "\n",
      "[39] K. G. Niederhoffer, J. W. Pennebaker. Linguistic style matching in\n",
      "social interaction. J. Lang. and Social Psych., 21(4):337–360, 2002.\n",
      "\n",
      "[40] J. Otterbacher, L. Hemphill. Learning the lingo? Gender, prestige\n",
      "and linguistic adaptation in review communities. Proceedings of\n",
      "CSCW, 2012.\n",
      "\n",
      "[41] J. W. Pennebaker, R. J. Booth, M. E. Francis. Linguistic inquiry and\n",
      "\n",
      "word count (LIWC): A computerized text analysis program.\n",
      "http://www.liwc.net/, 2007.\n",
      "\n",
      "[42] R. Rowe, G. Creamer, S. Hershkop, S. J. Stolfo. Automated social\n",
      "hierarchy detection through email network analysis. Proceedings of\n",
      "the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining\n",
      "and social network analysis, 109–117, 2007.\n",
      "\n",
      "[43] A. Scalia. Interview with Justice Antonin Scalia (transcript).\n",
      "\n",
      "C-SPAN (2009-06-19), 2009.\n",
      "\n",
      "[44] A. J. Scholand, Y. R. Tausczik, J. W. Pennebaker. Social language\n",
      "\n",
      "network analysis. CSCW, 23–26, 2010.\n",
      "\n",
      "[45] R. L. Street, H. Giles. Speech accommodation theory. Social\n",
      "\n",
      "cognition and communication. Sage Publications, 1982.\n",
      "\n",
      "[46] D. Taraborelli, G. L. Ciampaglia. Beyond notability. Collective\n",
      "\n",
      "deliberation on content inclusion in Wikipedia. Second international\n",
      "workshop on quality in techno-social systems, 2010.\n",
      "\n",
      "[47] J. Thakerar, H. Giles, J. Cheshire. Psychological and linguistic\n",
      "\n",
      "parameters of speech accommodation theory. Advances in the Social\n",
      "Psychology of Language. Cambridge, 1982.\n",
      "\n",
      "[48] S. Thye. A status value theory of power in exchange relations.\n",
      "\n",
      "American Sociological Review, 65:407–432, June 2000.\n",
      "\n",
      "[49] S. Thye, D. Willer, B. Markovsky. From status to power: New\n",
      "\n",
      "models at the intersection of two theories. Social Forces,\n",
      "84:1471–1495, 2006.\n",
      "\n",
      "[50] F. B. Viégas, M. Wattenberg, J. Kriss, F. van Ham. Talk before you\n",
      "\n",
      "type: Coordination in Wikipedia. HICSS, 78–78, 2007.\n",
      "\n",
      "[51] D. Willer. Network Exchange Theory. Praeger, 1999.\n",
      "[52] R. J. Wolfe, K. L. McGinn. Perceived relative power and its inﬂuence\n",
      "\n",
      "on negotiations. Group Decision and Negotiation, 14:3–20, 2005.\n",
      "\n",
      "[53] F. Wu, B. A. Huberman. Opinion formation under costly expression.\n",
      "\n",
      "ACMTrans. Intelligent Systems and Technology, 1(1):1–13, 2010.\n",
      "\n",
      "[54] F. Wu, B. A. Huberman, L. A. Adamic, J. R. Tyler. Information ﬂow\n",
      "\n",
      "in social groups. Physica A: Statistical and Theoretical Physics,\n",
      "337(1-2):327–335, 2004.\n",
      "\n",
      "WWW 2012 – Session: Social Interactions and the WebApril 16–20, 2012, Lyon, France708\f",
      "\n"
     ]
    }
   ],
   "source": [
    "pdfbytes = io.BytesIO(pdfrequest.content)\n",
    "pdfstring = readPDF(pdfbytes)\n",
    "print(pdfstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title, author, url, full text\n",
    "filename = pdfstring[:10]\n",
    "pdfdf = pandas.DataFrame({'filename': filename, 'url': pdfurl, 'content': pdfstring}, index = [1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echoes of</td>\n",
       "      <td>https://dl.acm.org/doi/pdf/10.1145/2187836.218...</td>\n",
       "      <td>Echoes of Power: Language Effects and Power Di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                                url  \\\n",
       "1  Echoes of   https://dl.acm.org/doi/pdf/10.1145/2187836.218...   \n",
       "\n",
       "                                             content  \n",
       "1  Echoes of Power: Language Effects and Power Di...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Exercise 4</font>\n",
    "\n",
    "<font color=\"red\">In the two cells immediately following, describe a possible project (e.g., it might end up being your final project, but need not be if you are still searching): **WHAT** you will analyze--the texts you will select and the social game, world and actors you intend to learn about through your analysis (<100 words); **WHY** you will analyze these texts to learn about that context--justify the rationale behind your proposed sample design for this project, based on the readings. What is the social game, social work, or social actors about whom you are seeking to make inferences? What are the virtues of your proposed sample with respect to your research questions? What are its limitations? What are alternatives? What would be a reasonable path to \"scale up\" your sample for further analysis (i.e., high-profile publication)? (<150 words)? [**Note**: your individual or collective project will change over the course of the quarter as new data and/or analysis opportunities arise or if old ones fade away.] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***What?*** \n",
    "<100 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use the pushshift Reddit data to analyze how academic ideas are used in online discourse. I want to understand how and when users (actors) in online environments (world) are inclined to invoke academic ideas, whether it is empirical research, theories, or media appearances, in order to speak with more weight in online discussions (game)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Why?***\n",
    "<150 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage in using pushshift Reddit data is manifold. First, compared with using the Reddit API, the data in pushshift is more readily accessible. Second, Reddit, as compared with Facebook, has better data access in general. Third, compared with Twitter, the platform affordances of Reddit allows for more elaborate and wordy political discussions.\n",
    "\n",
    "The disadvantages in using pushshift Reddit data is it's scale: since pushshift data is mainly accessible through batch downloads, it's harder to access only a subsection of all the content available. Pushshift data is also only a fraction of all the online discussions, and may contain a combination of platform, user, and accessibility bias. For example, according to [this site](https://www.statista.com/statistics/1255182/distribution-of-users-on-reddit-worldwide-gender/), Reddit users are composed of 63% male and 37% female.\n",
    "\n",
    "Alternative sources for online discussion using academic ideas may come from various question-and-answer forums, such as Quora, StackOverflow, and 知乎."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources:\n",
    "\n",
    "Other popular sources for internet data:\n",
    "\n",
    "[reddit](https://www.reddit.com/) - https://praw.readthedocs.io/en/v2.1.21/\n",
    "\n",
    "[twitter](https://twitter.com/) - https://pypi.org/project/python-twitter/\n",
    "\n",
    "[project gutenburg](https://www.gutenberg.org/) - https://github.com/ageitgey/Gutenberg \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
